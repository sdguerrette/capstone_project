{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6073e73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xlrd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sqlalchemy import create_engine\n",
    "from config import db_password\n",
    "import psycopg2\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c47c3d4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIPS</th>\n",
       "      <th>AREA_SQMI</th>\n",
       "      <th>E_TOTPOP</th>\n",
       "      <th>E_HU</th>\n",
       "      <th>E_HH</th>\n",
       "      <th>E_POV</th>\n",
       "      <th>E_UNEMP</th>\n",
       "      <th>E_PCI</th>\n",
       "      <th>E_NOHSDP</th>\n",
       "      <th>E_AGE65</th>\n",
       "      <th>...</th>\n",
       "      <th>Hopefulness</th>\n",
       "      <th>Income Per Capita</th>\n",
       "      <th>Neuroticism</th>\n",
       "      <th>Openness</th>\n",
       "      <th>Religiosity</th>\n",
       "      <th>Risk Taking</th>\n",
       "      <th>Selflessness</th>\n",
       "      <th>Tolerance</th>\n",
       "      <th>Work Ethic</th>\n",
       "      <th>first_yr_cases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>594.443459</td>\n",
       "      <td>55200</td>\n",
       "      <td>23315</td>\n",
       "      <td>21115</td>\n",
       "      <td>8422</td>\n",
       "      <td>1065</td>\n",
       "      <td>29372</td>\n",
       "      <td>4204</td>\n",
       "      <td>8050</td>\n",
       "      <td>...</td>\n",
       "      <td>91.163142</td>\n",
       "      <td>26168.0</td>\n",
       "      <td>77.925476</td>\n",
       "      <td>78.222354</td>\n",
       "      <td>91.106719</td>\n",
       "      <td>53.333333</td>\n",
       "      <td>82.142857</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>60.380952</td>\n",
       "      <td>6589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1009</td>\n",
       "      <td>644.830460</td>\n",
       "      <td>57645</td>\n",
       "      <td>24222</td>\n",
       "      <td>20600</td>\n",
       "      <td>8220</td>\n",
       "      <td>909</td>\n",
       "      <td>22656</td>\n",
       "      <td>7861</td>\n",
       "      <td>10233</td>\n",
       "      <td>...</td>\n",
       "      <td>79.492703</td>\n",
       "      <td>21033.0</td>\n",
       "      <td>78.764620</td>\n",
       "      <td>78.193105</td>\n",
       "      <td>92.045455</td>\n",
       "      <td>57.603815</td>\n",
       "      <td>79.307632</td>\n",
       "      <td>64.953288</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>6444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1013</td>\n",
       "      <td>776.838201</td>\n",
       "      <td>20025</td>\n",
       "      <td>10026</td>\n",
       "      <td>6708</td>\n",
       "      <td>4640</td>\n",
       "      <td>567</td>\n",
       "      <td>20430</td>\n",
       "      <td>2141</td>\n",
       "      <td>3806</td>\n",
       "      <td>...</td>\n",
       "      <td>83.523765</td>\n",
       "      <td>19011.0</td>\n",
       "      <td>78.563680</td>\n",
       "      <td>76.109761</td>\n",
       "      <td>76.623924</td>\n",
       "      <td>69.058104</td>\n",
       "      <td>79.956648</td>\n",
       "      <td>67.920284</td>\n",
       "      <td>72.773953</td>\n",
       "      <td>2097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1015</td>\n",
       "      <td>605.867251</td>\n",
       "      <td>115098</td>\n",
       "      <td>53682</td>\n",
       "      <td>45033</td>\n",
       "      <td>20819</td>\n",
       "      <td>4628</td>\n",
       "      <td>24706</td>\n",
       "      <td>12620</td>\n",
       "      <td>19386</td>\n",
       "      <td>...</td>\n",
       "      <td>83.365608</td>\n",
       "      <td>22231.0</td>\n",
       "      <td>79.439032</td>\n",
       "      <td>79.955121</td>\n",
       "      <td>77.918741</td>\n",
       "      <td>54.063568</td>\n",
       "      <td>76.745724</td>\n",
       "      <td>67.456150</td>\n",
       "      <td>68.292794</td>\n",
       "      <td>14224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1017</td>\n",
       "      <td>596.560643</td>\n",
       "      <td>33826</td>\n",
       "      <td>16981</td>\n",
       "      <td>13516</td>\n",
       "      <td>5531</td>\n",
       "      <td>773</td>\n",
       "      <td>22827</td>\n",
       "      <td>4383</td>\n",
       "      <td>6409</td>\n",
       "      <td>...</td>\n",
       "      <td>85.371517</td>\n",
       "      <td>21532.0</td>\n",
       "      <td>76.995358</td>\n",
       "      <td>78.156771</td>\n",
       "      <td>75.891100</td>\n",
       "      <td>67.343775</td>\n",
       "      <td>79.128558</td>\n",
       "      <td>66.397785</td>\n",
       "      <td>69.554441</td>\n",
       "      <td>3488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3053</th>\n",
       "      <td>48229</td>\n",
       "      <td>4570.523160</td>\n",
       "      <td>4098</td>\n",
       "      <td>1562</td>\n",
       "      <td>900</td>\n",
       "      <td>951</td>\n",
       "      <td>101</td>\n",
       "      <td>14190</td>\n",
       "      <td>1263</td>\n",
       "      <td>639</td>\n",
       "      <td>...</td>\n",
       "      <td>55.568966</td>\n",
       "      <td>14776.0</td>\n",
       "      <td>76.720396</td>\n",
       "      <td>79.603081</td>\n",
       "      <td>73.986415</td>\n",
       "      <td>70.917126</td>\n",
       "      <td>79.605796</td>\n",
       "      <td>75.878105</td>\n",
       "      <td>71.008448</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3054</th>\n",
       "      <td>48131</td>\n",
       "      <td>1793.476183</td>\n",
       "      <td>11355</td>\n",
       "      <td>5592</td>\n",
       "      <td>3511</td>\n",
       "      <td>2751</td>\n",
       "      <td>482</td>\n",
       "      <td>17864</td>\n",
       "      <td>2386</td>\n",
       "      <td>2025</td>\n",
       "      <td>...</td>\n",
       "      <td>77.899678</td>\n",
       "      <td>19853.0</td>\n",
       "      <td>79.125428</td>\n",
       "      <td>78.895880</td>\n",
       "      <td>76.629575</td>\n",
       "      <td>60.576045</td>\n",
       "      <td>73.670302</td>\n",
       "      <td>64.571017</td>\n",
       "      <td>68.007770</td>\n",
       "      <td>1214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3055</th>\n",
       "      <td>48505</td>\n",
       "      <td>998.411980</td>\n",
       "      <td>14369</td>\n",
       "      <td>6388</td>\n",
       "      <td>4405</td>\n",
       "      <td>5609</td>\n",
       "      <td>621</td>\n",
       "      <td>17228</td>\n",
       "      <td>3226</td>\n",
       "      <td>1999</td>\n",
       "      <td>...</td>\n",
       "      <td>86.586509</td>\n",
       "      <td>16007.0</td>\n",
       "      <td>79.355639</td>\n",
       "      <td>79.572483</td>\n",
       "      <td>74.378252</td>\n",
       "      <td>77.443239</td>\n",
       "      <td>76.386871</td>\n",
       "      <td>74.001471</td>\n",
       "      <td>73.609838</td>\n",
       "      <td>1760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3056</th>\n",
       "      <td>48507</td>\n",
       "      <td>1297.406535</td>\n",
       "      <td>12131</td>\n",
       "      <td>4344</td>\n",
       "      <td>3509</td>\n",
       "      <td>4150</td>\n",
       "      <td>421</td>\n",
       "      <td>13350</td>\n",
       "      <td>2719</td>\n",
       "      <td>1665</td>\n",
       "      <td>...</td>\n",
       "      <td>88.785822</td>\n",
       "      <td>13393.0</td>\n",
       "      <td>78.392216</td>\n",
       "      <td>76.024682</td>\n",
       "      <td>75.848196</td>\n",
       "      <td>76.967659</td>\n",
       "      <td>77.303576</td>\n",
       "      <td>70.010162</td>\n",
       "      <td>71.121990</td>\n",
       "      <td>1844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3057</th>\n",
       "      <td>48247</td>\n",
       "      <td>1136.172598</td>\n",
       "      <td>5282</td>\n",
       "      <td>2523</td>\n",
       "      <td>1710</td>\n",
       "      <td>1431</td>\n",
       "      <td>229</td>\n",
       "      <td>17798</td>\n",
       "      <td>812</td>\n",
       "      <td>932</td>\n",
       "      <td>...</td>\n",
       "      <td>82.727613</td>\n",
       "      <td>16637.0</td>\n",
       "      <td>80.157542</td>\n",
       "      <td>79.708963</td>\n",
       "      <td>74.399849</td>\n",
       "      <td>74.024835</td>\n",
       "      <td>77.564505</td>\n",
       "      <td>72.456881</td>\n",
       "      <td>70.160988</td>\n",
       "      <td>605</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3058 rows × 105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       FIPS    AREA_SQMI  E_TOTPOP   E_HU   E_HH  E_POV  E_UNEMP  E_PCI  \\\n",
       "0      1001   594.443459     55200  23315  21115   8422     1065  29372   \n",
       "1      1009   644.830460     57645  24222  20600   8220      909  22656   \n",
       "2      1013   776.838201     20025  10026   6708   4640      567  20430   \n",
       "3      1015   605.867251    115098  53682  45033  20819     4628  24706   \n",
       "4      1017   596.560643     33826  16981  13516   5531      773  22827   \n",
       "...     ...          ...       ...    ...    ...    ...      ...    ...   \n",
       "3053  48229  4570.523160      4098   1562    900    951      101  14190   \n",
       "3054  48131  1793.476183     11355   5592   3511   2751      482  17864   \n",
       "3055  48505   998.411980     14369   6388   4405   5609      621  17228   \n",
       "3056  48507  1297.406535     12131   4344   3509   4150      421  13350   \n",
       "3057  48247  1136.172598      5282   2523   1710   1431      229  17798   \n",
       "\n",
       "      E_NOHSDP  E_AGE65  ...  Hopefulness  Income Per Capita  Neuroticism  \\\n",
       "0         4204     8050  ...    91.163142            26168.0    77.925476   \n",
       "1         7861    10233  ...    79.492703            21033.0    78.764620   \n",
       "2         2141     3806  ...    83.523765            19011.0    78.563680   \n",
       "3        12620    19386  ...    83.365608            22231.0    79.439032   \n",
       "4         4383     6409  ...    85.371517            21532.0    76.995358   \n",
       "...        ...      ...  ...          ...                ...          ...   \n",
       "3053      1263      639  ...    55.568966            14776.0    76.720396   \n",
       "3054      2386     2025  ...    77.899678            19853.0    79.125428   \n",
       "3055      3226     1999  ...    86.586509            16007.0    79.355639   \n",
       "3056      2719     1665  ...    88.785822            13393.0    78.392216   \n",
       "3057       812      932  ...    82.727613            16637.0    80.157542   \n",
       "\n",
       "       Openness  Religiosity  Risk Taking  Selflessness  Tolerance  \\\n",
       "0     78.222354    91.106719    53.333333     82.142857  70.000000   \n",
       "1     78.193105    92.045455    57.603815     79.307632  64.953288   \n",
       "2     76.109761    76.623924    69.058104     79.956648  67.920284   \n",
       "3     79.955121    77.918741    54.063568     76.745724  67.456150   \n",
       "4     78.156771    75.891100    67.343775     79.128558  66.397785   \n",
       "...         ...          ...          ...           ...        ...   \n",
       "3053  79.603081    73.986415    70.917126     79.605796  75.878105   \n",
       "3054  78.895880    76.629575    60.576045     73.670302  64.571017   \n",
       "3055  79.572483    74.378252    77.443239     76.386871  74.001471   \n",
       "3056  76.024682    75.848196    76.967659     77.303576  70.010162   \n",
       "3057  79.708963    74.399849    74.024835     77.564505  72.456881   \n",
       "\n",
       "      Work Ethic  first_yr_cases  \n",
       "0      60.380952            6589  \n",
       "1      76.000000            6444  \n",
       "2      72.773953            2097  \n",
       "3      68.292794           14224  \n",
       "4      69.554441            3488  \n",
       "...          ...             ...  \n",
       "3053   71.008448             512  \n",
       "3054   68.007770            1214  \n",
       "3055   73.609838            1760  \n",
       "3056   71.121990            1844  \n",
       "3057   70.160988             605  \n",
       "\n",
       "[3058 rows x 105 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create engine and connect to AWS RDS\n",
    "db_string = f\"postgresql://postgres:{db_password}@capstone-db.cutxgn80t57o.us-west-1.rds.amazonaws.com\"\n",
    "engine = create_engine(db_string)\n",
    "# read and check merged cases table\n",
    "df = pd.read_sql('cases_merged_full', con = engine)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c44e314e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set index to FIPS\n",
    "df = df.set_index(df['FIPS'])\n",
    "df= df.drop(['FIPS'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e97997a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use regex to split svi columns into distinct categories\n",
    "cols = df.columns.to_list()\n",
    "col_series = pd.Series(cols)\n",
    "pct_str = r'^[ERS]P+.'\n",
    "pct_form = col_series.str.contains(pct_str)\n",
    "pct_col = col_series[pct_form].to_list()\n",
    "flag_str = r'^F+.'\n",
    "flag_form = col_series.str.contains(flag_str)\n",
    "flag_col = col_series[flag_form].to_list()\n",
    "val_str = r'^E_+.'\n",
    "val_form = col_series.str.contains(val_str)\n",
    "val_col = col_series[val_form].to_list()\n",
    "non_svi = col_series[~pct_form & ~flag_form & ~val_form].to_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f26935a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter cases_df to only have svi estimated percentage columns\n",
    "cases_df = df.drop(columns = flag_col)\n",
    "cases_df = cases_df.drop(columns = val_col)\n",
    "cases_df.columns.to_list()\n",
    "cases_df = cases_df.merge(df['E_TOTPOP'], how = 'left', left_index=True, right_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3286057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AREA_SQMI',\n",
       " 'EP_POV',\n",
       " 'EP_UNEMP',\n",
       " 'EP_PCI',\n",
       " 'EP_NOHSDP',\n",
       " 'EP_AGE65',\n",
       " 'EP_AGE17',\n",
       " 'EP_DISABL',\n",
       " 'EP_SNGPNT',\n",
       " 'EP_MINRTY',\n",
       " 'EP_LIMENG',\n",
       " 'EP_MUNIT',\n",
       " 'EP_MOBILE',\n",
       " 'EP_CROWD',\n",
       " 'EP_NOVEH',\n",
       " 'EP_GROUPQ',\n",
       " 'EPL_POV',\n",
       " 'EPL_UNEMP',\n",
       " 'EPL_PCI',\n",
       " 'EPL_NOHSDP',\n",
       " 'SPL_THEME1',\n",
       " 'RPL_THEME1',\n",
       " 'EPL_AGE65',\n",
       " 'EPL_AGE17',\n",
       " 'EPL_DISABL',\n",
       " 'EPL_SNGPNT',\n",
       " 'SPL_THEME2',\n",
       " 'RPL_THEME2',\n",
       " 'EPL_MINRTY',\n",
       " 'EPL_LIMENG',\n",
       " 'SPL_THEME3',\n",
       " 'RPL_THEME3',\n",
       " 'EPL_MUNIT',\n",
       " 'EPL_MOBILE',\n",
       " 'EPL_CROWD',\n",
       " 'EPL_NOVEH',\n",
       " 'EPL_GROUPQ',\n",
       " 'SPL_THEME4',\n",
       " 'RPL_THEME4',\n",
       " 'SPL_THEMES',\n",
       " 'RPL_THEMES',\n",
       " 'EP_UNINSUR',\n",
       " 'num_beds',\n",
       " 'dem_pct',\n",
       " 'Agreeableness',\n",
       " 'Belief In Science',\n",
       " 'Collectivism',\n",
       " 'Conflict Awareness',\n",
       " 'Conscientiousness',\n",
       " 'Empathy',\n",
       " 'Employment Rate',\n",
       " 'Entrepreneurship',\n",
       " 'Extraversion',\n",
       " 'Gender Equality',\n",
       " 'Hopefulness',\n",
       " 'Income Per Capita',\n",
       " 'Neuroticism',\n",
       " 'Openness',\n",
       " 'Religiosity',\n",
       " 'Risk Taking',\n",
       " 'Selflessness',\n",
       " 'Tolerance',\n",
       " 'Work Ethic',\n",
       " 'first_yr_cases',\n",
       " 'E_TOTPOP']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cases_df.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fdcc35d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AREA_SQMI</th>\n",
       "      <th>EP_POV</th>\n",
       "      <th>EP_UNEMP</th>\n",
       "      <th>EP_PCI</th>\n",
       "      <th>EP_NOHSDP</th>\n",
       "      <th>EP_AGE65</th>\n",
       "      <th>EP_AGE17</th>\n",
       "      <th>EP_DISABL</th>\n",
       "      <th>EP_SNGPNT</th>\n",
       "      <th>EP_MINRTY</th>\n",
       "      <th>...</th>\n",
       "      <th>Income Per Capita</th>\n",
       "      <th>Neuroticism</th>\n",
       "      <th>Openness</th>\n",
       "      <th>Religiosity</th>\n",
       "      <th>Risk Taking</th>\n",
       "      <th>Selflessness</th>\n",
       "      <th>Tolerance</th>\n",
       "      <th>Work Ethic</th>\n",
       "      <th>first_yr_cases</th>\n",
       "      <th>E_TOTPOP</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FIPS</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>594.443459</td>\n",
       "      <td>15.4</td>\n",
       "      <td>4.2</td>\n",
       "      <td>29372.0</td>\n",
       "      <td>11.3</td>\n",
       "      <td>14.6</td>\n",
       "      <td>24.2</td>\n",
       "      <td>19.3</td>\n",
       "      <td>7.5</td>\n",
       "      <td>25.0</td>\n",
       "      <td>...</td>\n",
       "      <td>26168.0</td>\n",
       "      <td>77.925476</td>\n",
       "      <td>78.222354</td>\n",
       "      <td>91.106719</td>\n",
       "      <td>53.333333</td>\n",
       "      <td>82.142857</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>60.380952</td>\n",
       "      <td>6589</td>\n",
       "      <td>55200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>644.830460</td>\n",
       "      <td>14.4</td>\n",
       "      <td>4.1</td>\n",
       "      <td>22656.0</td>\n",
       "      <td>19.8</td>\n",
       "      <td>17.8</td>\n",
       "      <td>23.4</td>\n",
       "      <td>14.2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>12.9</td>\n",
       "      <td>...</td>\n",
       "      <td>21033.0</td>\n",
       "      <td>78.764620</td>\n",
       "      <td>78.193105</td>\n",
       "      <td>92.045455</td>\n",
       "      <td>57.603815</td>\n",
       "      <td>79.307632</td>\n",
       "      <td>64.953288</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>6444</td>\n",
       "      <td>57645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013</th>\n",
       "      <td>776.838201</td>\n",
       "      <td>23.5</td>\n",
       "      <td>6.7</td>\n",
       "      <td>20430.0</td>\n",
       "      <td>15.4</td>\n",
       "      <td>19.0</td>\n",
       "      <td>22.8</td>\n",
       "      <td>17.7</td>\n",
       "      <td>10.5</td>\n",
       "      <td>48.1</td>\n",
       "      <td>...</td>\n",
       "      <td>19011.0</td>\n",
       "      <td>78.563680</td>\n",
       "      <td>76.109761</td>\n",
       "      <td>76.623924</td>\n",
       "      <td>69.058104</td>\n",
       "      <td>79.956648</td>\n",
       "      <td>67.920284</td>\n",
       "      <td>72.773953</td>\n",
       "      <td>2097</td>\n",
       "      <td>20025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015</th>\n",
       "      <td>605.867251</td>\n",
       "      <td>18.6</td>\n",
       "      <td>8.8</td>\n",
       "      <td>24706.0</td>\n",
       "      <td>15.9</td>\n",
       "      <td>16.8</td>\n",
       "      <td>21.9</td>\n",
       "      <td>20.8</td>\n",
       "      <td>10.4</td>\n",
       "      <td>27.5</td>\n",
       "      <td>...</td>\n",
       "      <td>22231.0</td>\n",
       "      <td>79.439032</td>\n",
       "      <td>79.955121</td>\n",
       "      <td>77.918741</td>\n",
       "      <td>54.063568</td>\n",
       "      <td>76.745724</td>\n",
       "      <td>67.456150</td>\n",
       "      <td>68.292794</td>\n",
       "      <td>14224</td>\n",
       "      <td>115098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017</th>\n",
       "      <td>596.560643</td>\n",
       "      <td>16.6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>22827.0</td>\n",
       "      <td>18.6</td>\n",
       "      <td>18.9</td>\n",
       "      <td>20.7</td>\n",
       "      <td>16.7</td>\n",
       "      <td>9.7</td>\n",
       "      <td>44.2</td>\n",
       "      <td>...</td>\n",
       "      <td>21532.0</td>\n",
       "      <td>76.995358</td>\n",
       "      <td>78.156771</td>\n",
       "      <td>75.891100</td>\n",
       "      <td>67.343775</td>\n",
       "      <td>79.128558</td>\n",
       "      <td>66.397785</td>\n",
       "      <td>69.554441</td>\n",
       "      <td>3488</td>\n",
       "      <td>33826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48229</th>\n",
       "      <td>4570.523160</td>\n",
       "      <td>28.2</td>\n",
       "      <td>8.3</td>\n",
       "      <td>14190.0</td>\n",
       "      <td>46.1</td>\n",
       "      <td>15.6</td>\n",
       "      <td>23.9</td>\n",
       "      <td>27.2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>82.4</td>\n",
       "      <td>...</td>\n",
       "      <td>14776.0</td>\n",
       "      <td>76.720396</td>\n",
       "      <td>79.603081</td>\n",
       "      <td>73.986415</td>\n",
       "      <td>70.917126</td>\n",
       "      <td>79.605796</td>\n",
       "      <td>75.878105</td>\n",
       "      <td>71.008448</td>\n",
       "      <td>512</td>\n",
       "      <td>4098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48131</th>\n",
       "      <td>1793.476183</td>\n",
       "      <td>25.6</td>\n",
       "      <td>10.6</td>\n",
       "      <td>17864.0</td>\n",
       "      <td>32.9</td>\n",
       "      <td>17.8</td>\n",
       "      <td>26.1</td>\n",
       "      <td>26.2</td>\n",
       "      <td>15.8</td>\n",
       "      <td>90.9</td>\n",
       "      <td>...</td>\n",
       "      <td>19853.0</td>\n",
       "      <td>79.125428</td>\n",
       "      <td>78.895880</td>\n",
       "      <td>76.629575</td>\n",
       "      <td>60.576045</td>\n",
       "      <td>73.670302</td>\n",
       "      <td>64.571017</td>\n",
       "      <td>68.007770</td>\n",
       "      <td>1214</td>\n",
       "      <td>11355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48505</th>\n",
       "      <td>998.411980</td>\n",
       "      <td>39.5</td>\n",
       "      <td>11.0</td>\n",
       "      <td>17228.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>13.9</td>\n",
       "      <td>33.6</td>\n",
       "      <td>17.3</td>\n",
       "      <td>17.1</td>\n",
       "      <td>95.7</td>\n",
       "      <td>...</td>\n",
       "      <td>16007.0</td>\n",
       "      <td>79.355639</td>\n",
       "      <td>79.572483</td>\n",
       "      <td>74.378252</td>\n",
       "      <td>77.443239</td>\n",
       "      <td>76.386871</td>\n",
       "      <td>74.001471</td>\n",
       "      <td>73.609838</td>\n",
       "      <td>1760</td>\n",
       "      <td>14369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48507</th>\n",
       "      <td>1297.406535</td>\n",
       "      <td>34.8</td>\n",
       "      <td>8.4</td>\n",
       "      <td>13350.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>13.7</td>\n",
       "      <td>29.5</td>\n",
       "      <td>23.3</td>\n",
       "      <td>16.1</td>\n",
       "      <td>95.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13393.0</td>\n",
       "      <td>78.392216</td>\n",
       "      <td>76.024682</td>\n",
       "      <td>75.848196</td>\n",
       "      <td>76.967659</td>\n",
       "      <td>77.303576</td>\n",
       "      <td>70.010162</td>\n",
       "      <td>71.121990</td>\n",
       "      <td>1844</td>\n",
       "      <td>12131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48247</th>\n",
       "      <td>1136.172598</td>\n",
       "      <td>27.4</td>\n",
       "      <td>11.5</td>\n",
       "      <td>17798.0</td>\n",
       "      <td>25.8</td>\n",
       "      <td>17.6</td>\n",
       "      <td>31.4</td>\n",
       "      <td>26.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>93.0</td>\n",
       "      <td>...</td>\n",
       "      <td>16637.0</td>\n",
       "      <td>80.157542</td>\n",
       "      <td>79.708963</td>\n",
       "      <td>74.399849</td>\n",
       "      <td>74.024835</td>\n",
       "      <td>77.564505</td>\n",
       "      <td>72.456881</td>\n",
       "      <td>70.160988</td>\n",
       "      <td>605</td>\n",
       "      <td>5282</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3034 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         AREA_SQMI  EP_POV  EP_UNEMP   EP_PCI  EP_NOHSDP  EP_AGE65  EP_AGE17  \\\n",
       "FIPS                                                                           \n",
       "1001    594.443459    15.4       4.2  29372.0       11.3      14.6      24.2   \n",
       "1009    644.830460    14.4       4.1  22656.0       19.8      17.8      23.4   \n",
       "1013    776.838201    23.5       6.7  20430.0       15.4      19.0      22.8   \n",
       "1015    605.867251    18.6       8.8  24706.0       15.9      16.8      21.9   \n",
       "1017    596.560643    16.6       5.0  22827.0       18.6      18.9      20.7   \n",
       "...            ...     ...       ...      ...        ...       ...       ...   \n",
       "48229  4570.523160    28.2       8.3  14190.0       46.1      15.6      23.9   \n",
       "48131  1793.476183    25.6      10.6  17864.0       32.9      17.8      26.1   \n",
       "48505   998.411980    39.5      11.0  17228.0       40.0      13.9      33.6   \n",
       "48507  1297.406535    34.8       8.4  13350.0       38.0      13.7      29.5   \n",
       "48247  1136.172598    27.4      11.5  17798.0       25.8      17.6      31.4   \n",
       "\n",
       "       EP_DISABL  EP_SNGPNT  EP_MINRTY  ...  Income Per Capita  Neuroticism  \\\n",
       "FIPS                                    ...                                   \n",
       "1001        19.3        7.5       25.0  ...            26168.0    77.925476   \n",
       "1009        14.2        7.0       12.9  ...            21033.0    78.764620   \n",
       "1013        17.7       10.5       48.1  ...            19011.0    78.563680   \n",
       "1015        20.8       10.4       27.5  ...            22231.0    79.439032   \n",
       "1017        16.7        9.7       44.2  ...            21532.0    76.995358   \n",
       "...          ...        ...        ...  ...                ...          ...   \n",
       "48229       27.2        8.0       82.4  ...            14776.0    76.720396   \n",
       "48131       26.2       15.8       90.9  ...            19853.0    79.125428   \n",
       "48505       17.3       17.1       95.7  ...            16007.0    79.355639   \n",
       "48507       23.3       16.1       95.0  ...            13393.0    78.392216   \n",
       "48247       26.0       15.2       93.0  ...            16637.0    80.157542   \n",
       "\n",
       "        Openness  Religiosity  Risk Taking  Selflessness  Tolerance  \\\n",
       "FIPS                                                                  \n",
       "1001   78.222354    91.106719    53.333333     82.142857  70.000000   \n",
       "1009   78.193105    92.045455    57.603815     79.307632  64.953288   \n",
       "1013   76.109761    76.623924    69.058104     79.956648  67.920284   \n",
       "1015   79.955121    77.918741    54.063568     76.745724  67.456150   \n",
       "1017   78.156771    75.891100    67.343775     79.128558  66.397785   \n",
       "...          ...          ...          ...           ...        ...   \n",
       "48229  79.603081    73.986415    70.917126     79.605796  75.878105   \n",
       "48131  78.895880    76.629575    60.576045     73.670302  64.571017   \n",
       "48505  79.572483    74.378252    77.443239     76.386871  74.001471   \n",
       "48507  76.024682    75.848196    76.967659     77.303576  70.010162   \n",
       "48247  79.708963    74.399849    74.024835     77.564505  72.456881   \n",
       "\n",
       "       Work Ethic  first_yr_cases  E_TOTPOP  \n",
       "FIPS                                         \n",
       "1001    60.380952            6589     55200  \n",
       "1009    76.000000            6444     57645  \n",
       "1013    72.773953            2097     20025  \n",
       "1015    68.292794           14224    115098  \n",
       "1017    69.554441            3488     33826  \n",
       "...           ...             ...       ...  \n",
       "48229   71.008448             512      4098  \n",
       "48131   68.007770            1214     11355  \n",
       "48505   73.609838            1760     14369  \n",
       "48507   71.121990            1844     12131  \n",
       "48247   70.160988             605      5282  \n",
       "\n",
       "[3034 rows x 65 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop counties with 0 cases \n",
    "## these seem to be errors- mostly in Utah, some counties with large populations\n",
    "zeros = cases_df.loc[cases_df['first_yr_cases']==0]\n",
    "cases_df = cases_df.drop(index = zeros.index)\n",
    "cases_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "106bfab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FIPS\n",
       "1001    11.936594\n",
       "1009    11.178767\n",
       "1013    10.471910\n",
       "1015    12.358164\n",
       "1017    10.311595\n",
       "Name: case_pct, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create variable for case% for each counties population\n",
    "cases_df['case_pct'] = cases_df['first_yr_cases']/cases_df['E_TOTPOP']*100\n",
    "cases_df['case_pct'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c977cd6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    3034.000000\n",
       "mean        9.501167\n",
       "std         2.939667\n",
       "min         0.271796\n",
       "25%         7.766193\n",
       "50%         9.486029\n",
       "75%        11.180321\n",
       "max        38.010657\n",
       "Name: case_pct, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cases_df['case_pct'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73aa10ce",
   "metadata": {},
   "source": [
    "## RF Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7384c664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3034, 66)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cases_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8242a445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature set (x)\n",
    "X = cases_df.drop(['first_yr_cases','case_pct','num_beds'], axis=1).values\n",
    "\n",
    "#Define (y)\n",
    "y= cases_df['case_pct'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "426b3d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check columns list\n",
    "# X.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "44b3e403",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# frequency histogram to see how many counties are high risk and low risk\n",
    "plt.hist(cases_df[\"case_pct\"])\n",
    "plt.xlabel(\"High Risk Counties\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fd26af29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data for training and testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3 ,random_state= 42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cb794166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2123, 63)\n",
      "(911, 63)\n",
      "(2123,)\n",
      "(911,)\n"
     ]
    }
   ],
   "source": [
    "# Determine the shape of our training and testing sets.\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab34a44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f0a2871d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a StandardScaler instance.\n",
    "scaler = StandardScaler()\n",
    "# Fitting the Standard Scaler with the training data.\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scaling the data.\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d8a29ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 256)               16384     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 57,601\n",
      "Trainable params: 57,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-15 19:41:57.201991: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net\n",
    "number_input_features = len(X_train[0])\n",
    "hidden_nodes_layer1 = 256\n",
    "hidden_nodes_layer2 = 128\n",
    "hidden_nodes_layer3 = 64\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"relu\"))\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"linear\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "077c762e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=[\"mean_absolute_error\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3a8951c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "67/67 [==============================] - 1s 5ms/step - loss: 3.4942 - mean_absolute_error: 3.4942\n",
      "Epoch 2/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 2.0936 - mean_absolute_error: 2.0936\n",
      "Epoch 3/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 1.9004 - mean_absolute_error: 1.9004\n",
      "Epoch 4/300\n",
      "67/67 [==============================] - 0s 5ms/step - loss: 1.8030 - mean_absolute_error: 1.8030\n",
      "Epoch 5/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 1.6871 - mean_absolute_error: 1.6871\n",
      "Epoch 6/300\n",
      "67/67 [==============================] - 0s 5ms/step - loss: 1.6364 - mean_absolute_error: 1.6364\n",
      "Epoch 7/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 1.5623 - mean_absolute_error: 1.5623\n",
      "Epoch 8/300\n",
      "67/67 [==============================] - 0s 5ms/step - loss: 1.5042 - mean_absolute_error: 1.5042\n",
      "Epoch 9/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 1.4448 - mean_absolute_error: 1.4448\n",
      "Epoch 10/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 1.4228 - mean_absolute_error: 1.4228\n",
      "Epoch 11/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 1.3736 - mean_absolute_error: 1.3736\n",
      "Epoch 12/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 1.2983 - mean_absolute_error: 1.2983\n",
      "Epoch 13/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 1.2904 - mean_absolute_error: 1.2904\n",
      "Epoch 14/300\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 1.2233 - mean_absolute_error: 1.2233\n",
      "Epoch 15/300\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 1.1889 - mean_absolute_error: 1.1889\n",
      "Epoch 16/300\n",
      "67/67 [==============================] - 0s 5ms/step - loss: 1.1162 - mean_absolute_error: 1.1162\n",
      "Epoch 17/300\n",
      "67/67 [==============================] - 0s 5ms/step - loss: 1.1140 - mean_absolute_error: 1.1140\n",
      "Epoch 18/300\n",
      "67/67 [==============================] - 0s 5ms/step - loss: 1.0577 - mean_absolute_error: 1.0577\n",
      "Epoch 19/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 1.0310 - mean_absolute_error: 1.0310\n",
      "Epoch 20/300\n",
      "67/67 [==============================] - 0s 5ms/step - loss: 1.0279 - mean_absolute_error: 1.0279\n",
      "Epoch 21/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 1.0156 - mean_absolute_error: 1.0156\n",
      "Epoch 22/300\n",
      "67/67 [==============================] - 0s 5ms/step - loss: 0.9368 - mean_absolute_error: 0.9368\n",
      "Epoch 23/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.8829 - mean_absolute_error: 0.8829\n",
      "Epoch 24/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.8923 - mean_absolute_error: 0.8923\n",
      "Epoch 25/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.9023 - mean_absolute_error: 0.9023\n",
      "Epoch 26/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.8661 - mean_absolute_error: 0.8661\n",
      "Epoch 27/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.8430 - mean_absolute_error: 0.8430\n",
      "Epoch 28/300\n",
      "67/67 [==============================] - 0s 5ms/step - loss: 0.8394 - mean_absolute_error: 0.8394\n",
      "Epoch 29/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.8032 - mean_absolute_error: 0.8032\n",
      "Epoch 30/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.7819 - mean_absolute_error: 0.7819\n",
      "Epoch 31/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.7165 - mean_absolute_error: 0.7165\n",
      "Epoch 32/300\n",
      "67/67 [==============================] - 0s 5ms/step - loss: 0.6882 - mean_absolute_error: 0.6882\n",
      "Epoch 33/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6798 - mean_absolute_error: 0.6798\n",
      "Epoch 34/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.7084 - mean_absolute_error: 0.7084\n",
      "Epoch 35/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6705 - mean_absolute_error: 0.6705\n",
      "Epoch 36/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.6686 - mean_absolute_error: 0.6686\n",
      "Epoch 37/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.6090 - mean_absolute_error: 0.6090\n",
      "Epoch 38/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.6507 - mean_absolute_error: 0.6507\n",
      "Epoch 39/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.6101 - mean_absolute_error: 0.6101\n",
      "Epoch 40/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.5848 - mean_absolute_error: 0.5848\n",
      "Epoch 41/300\n",
      "67/67 [==============================] - 0s 5ms/step - loss: 0.5913 - mean_absolute_error: 0.5913\n",
      "Epoch 42/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.5776 - mean_absolute_error: 0.5776\n",
      "Epoch 43/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.5657 - mean_absolute_error: 0.5657\n",
      "Epoch 44/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.5636 - mean_absolute_error: 0.5636\n",
      "Epoch 45/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.5904 - mean_absolute_error: 0.5904\n",
      "Epoch 46/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.5249 - mean_absolute_error: 0.5249\n",
      "Epoch 47/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.5565 - mean_absolute_error: 0.5565\n",
      "Epoch 48/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.5074 - mean_absolute_error: 0.5074\n",
      "Epoch 49/300\n",
      "67/67 [==============================] - 0s 5ms/step - loss: 0.5184 - mean_absolute_error: 0.5184\n",
      "Epoch 50/300\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 0.5148 - mean_absolute_error: 0.5148\n",
      "Epoch 51/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.5069 - mean_absolute_error: 0.5069\n",
      "Epoch 52/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.5020 - mean_absolute_error: 0.5020\n",
      "Epoch 53/300\n",
      "67/67 [==============================] - 0s 5ms/step - loss: 0.5387 - mean_absolute_error: 0.5387\n",
      "Epoch 54/300\n",
      "67/67 [==============================] - 0s 5ms/step - loss: 0.4704 - mean_absolute_error: 0.4704\n",
      "Epoch 55/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.5125 - mean_absolute_error: 0.5125\n",
      "Epoch 56/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.5823 - mean_absolute_error: 0.5823\n",
      "Epoch 57/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.5066 - mean_absolute_error: 0.5066\n",
      "Epoch 58/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.5088 - mean_absolute_error: 0.5088\n",
      "Epoch 59/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.4426 - mean_absolute_error: 0.4426\n",
      "Epoch 60/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.4588 - mean_absolute_error: 0.4588\n",
      "Epoch 61/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.4581 - mean_absolute_error: 0.4581\n",
      "Epoch 62/300\n",
      "67/67 [==============================] - 0s 5ms/step - loss: 0.4411 - mean_absolute_error: 0.4411\n",
      "Epoch 63/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.4707 - mean_absolute_error: 0.4707\n",
      "Epoch 64/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.4531 - mean_absolute_error: 0.4531\n",
      "Epoch 65/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.4325 - mean_absolute_error: 0.4325\n",
      "Epoch 66/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.4305 - mean_absolute_error: 0.4305\n",
      "Epoch 67/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.4241 - mean_absolute_error: 0.4241\n",
      "Epoch 68/300\n",
      "67/67 [==============================] - 0s 5ms/step - loss: 0.4137 - mean_absolute_error: 0.4137\n",
      "Epoch 69/300\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 0.4264 - mean_absolute_error: 0.4264\n",
      "Epoch 70/300\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 0.4037 - mean_absolute_error: 0.4037\n",
      "Epoch 71/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.4272 - mean_absolute_error: 0.4272\n",
      "Epoch 72/300\n",
      "67/67 [==============================] - 0s 5ms/step - loss: 0.4138 - mean_absolute_error: 0.4138\n",
      "Epoch 73/300\n",
      "67/67 [==============================] - 0s 5ms/step - loss: 0.3973 - mean_absolute_error: 0.3973\n",
      "Epoch 74/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 0s 5ms/step - loss: 0.3868 - mean_absolute_error: 0.3868\n",
      "Epoch 75/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.4031 - mean_absolute_error: 0.4031\n",
      "Epoch 76/300\n",
      "67/67 [==============================] - 0s 5ms/step - loss: 0.4506 - mean_absolute_error: 0.4506\n",
      "Epoch 77/300\n",
      "67/67 [==============================] - 0s 5ms/step - loss: 0.4085 - mean_absolute_error: 0.4085\n",
      "Epoch 78/300\n",
      "67/67 [==============================] - 0s 5ms/step - loss: 0.4117 - mean_absolute_error: 0.4117\n",
      "Epoch 79/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.3958 - mean_absolute_error: 0.3958\n",
      "Epoch 80/300\n",
      "67/67 [==============================] - 0s 5ms/step - loss: 0.3834 - mean_absolute_error: 0.3834\n",
      "Epoch 81/300\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 0.3763 - mean_absolute_error: 0.3763\n",
      "Epoch 82/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.3635 - mean_absolute_error: 0.3635\n",
      "Epoch 83/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.4145 - mean_absolute_error: 0.4145\n",
      "Epoch 84/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.3589 - mean_absolute_error: 0.3589\n",
      "Epoch 85/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.3610 - mean_absolute_error: 0.3610\n",
      "Epoch 86/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.3929 - mean_absolute_error: 0.3929\n",
      "Epoch 87/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.3560 - mean_absolute_error: 0.3560\n",
      "Epoch 88/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.3662 - mean_absolute_error: 0.3662\n",
      "Epoch 89/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.4036 - mean_absolute_error: 0.4036\n",
      "Epoch 90/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.3735 - mean_absolute_error: 0.3735\n",
      "Epoch 91/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.3606 - mean_absolute_error: 0.3606\n",
      "Epoch 92/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.3578 - mean_absolute_error: 0.3578\n",
      "Epoch 93/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.3243 - mean_absolute_error: 0.3243\n",
      "Epoch 94/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.3522 - mean_absolute_error: 0.3522\n",
      "Epoch 95/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.3692 - mean_absolute_error: 0.3692\n",
      "Epoch 96/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.3363 - mean_absolute_error: 0.3363\n",
      "Epoch 97/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.3517 - mean_absolute_error: 0.3517\n",
      "Epoch 98/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.3838 - mean_absolute_error: 0.3838\n",
      "Epoch 99/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.3527 - mean_absolute_error: 0.3527\n",
      "Epoch 100/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.3623 - mean_absolute_error: 0.3623\n",
      "Epoch 101/300\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 0.3701 - mean_absolute_error: 0.3701\n",
      "Epoch 102/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.3758 - mean_absolute_error: 0.3758\n",
      "Epoch 103/300\n",
      "67/67 [==============================] - 0s 5ms/step - loss: 0.3351 - mean_absolute_error: 0.3351\n",
      "Epoch 104/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.3374 - mean_absolute_error: 0.3374\n",
      "Epoch 105/300\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 0.3614 - mean_absolute_error: 0.3614\n",
      "Epoch 106/300\n",
      "67/67 [==============================] - 0s 5ms/step - loss: 0.3447 - mean_absolute_error: 0.3447\n",
      "Epoch 107/300\n",
      "67/67 [==============================] - 0s 5ms/step - loss: 0.3346 - mean_absolute_error: 0.3346\n",
      "Epoch 108/300\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 0.3499 - mean_absolute_error: 0.3499\n",
      "Epoch 109/300\n",
      "67/67 [==============================] - 0s 5ms/step - loss: 0.3320 - mean_absolute_error: 0.3320\n",
      "Epoch 110/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.3532 - mean_absolute_error: 0.3532\n",
      "Epoch 111/300\n",
      "67/67 [==============================] - 0s 5ms/step - loss: 0.3469 - mean_absolute_error: 0.3469\n",
      "Epoch 112/300\n",
      "67/67 [==============================] - 0s 5ms/step - loss: 0.3282 - mean_absolute_error: 0.3282\n",
      "Epoch 113/300\n",
      "67/67 [==============================] - 0s 5ms/step - loss: 0.3298 - mean_absolute_error: 0.3298\n",
      "Epoch 114/300\n",
      "67/67 [==============================] - 0s 5ms/step - loss: 0.3347 - mean_absolute_error: 0.3347\n",
      "Epoch 115/300\n",
      "67/67 [==============================] - 0s 5ms/step - loss: 0.3131 - mean_absolute_error: 0.3131\n",
      "Epoch 116/300\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 0.3317 - mean_absolute_error: 0.3317\n",
      "Epoch 117/300\n",
      "67/67 [==============================] - 0s 5ms/step - loss: 0.3773 - mean_absolute_error: 0.3773\n",
      "Epoch 118/300\n",
      "67/67 [==============================] - 0s 5ms/step - loss: 0.3385 - mean_absolute_error: 0.3385\n",
      "Epoch 119/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.3251 - mean_absolute_error: 0.3251\n",
      "Epoch 120/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.3112 - mean_absolute_error: 0.3112\n",
      "Epoch 121/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.3800 - mean_absolute_error: 0.3800\n",
      "Epoch 122/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.3434 - mean_absolute_error: 0.3434\n",
      "Epoch 123/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.3002 - mean_absolute_error: 0.3002\n",
      "Epoch 124/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.3145 - mean_absolute_error: 0.3145\n",
      "Epoch 125/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.3095 - mean_absolute_error: 0.3095\n",
      "Epoch 126/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.3236 - mean_absolute_error: 0.3236\n",
      "Epoch 127/300\n",
      "67/67 [==============================] - 0s 5ms/step - loss: 0.3215 - mean_absolute_error: 0.3215\n",
      "Epoch 128/300\n",
      "67/67 [==============================] - 0s 5ms/step - loss: 0.3028 - mean_absolute_error: 0.3028\n",
      "Epoch 129/300\n",
      "67/67 [==============================] - 0s 5ms/step - loss: 0.3005 - mean_absolute_error: 0.3005\n",
      "Epoch 130/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.3287 - mean_absolute_error: 0.3287\n",
      "Epoch 131/300\n",
      "67/67 [==============================] - 0s 5ms/step - loss: 0.3084 - mean_absolute_error: 0.3084\n",
      "Epoch 132/300\n",
      "67/67 [==============================] - 0s 5ms/step - loss: 0.3148 - mean_absolute_error: 0.3148\n",
      "Epoch 133/300\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 0.3028 - mean_absolute_error: 0.3028\n",
      "Epoch 134/300\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.3000 - mean_absolute_error: 0.3000\n",
      "Epoch 135/300\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.3186 - mean_absolute_error: 0.3186\n",
      "Epoch 136/300\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.3446 - mean_absolute_error: 0.3446\n",
      "Epoch 137/300\n",
      "67/67 [==============================] - 0s 5ms/step - loss: 0.3178 - mean_absolute_error: 0.3178\n",
      "Epoch 138/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.3257 - mean_absolute_error: 0.3257\n",
      "Epoch 139/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.3377 - mean_absolute_error: 0.3377\n",
      "Epoch 140/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.3006 - mean_absolute_error: 0.3006\n",
      "Epoch 141/300\n",
      "67/67 [==============================] - 0s 5ms/step - loss: 0.3064 - mean_absolute_error: 0.3064\n",
      "Epoch 142/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2926 - mean_absolute_error: 0.2926\n",
      "Epoch 143/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2877 - mean_absolute_error: 0.2877\n",
      "Epoch 144/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2901 - mean_absolute_error: 0.2901\n",
      "Epoch 145/300\n",
      "67/67 [==============================] - 0s 5ms/step - loss: 0.3053 - mean_absolute_error: 0.3053\n",
      "Epoch 146/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.3089 - mean_absolute_error: 0.3089\n",
      "Epoch 147/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 0s 4ms/step - loss: 0.2909 - mean_absolute_error: 0.2909\n",
      "Epoch 148/300\n",
      "67/67 [==============================] - 0s 5ms/step - loss: 0.2783 - mean_absolute_error: 0.2783\n",
      "Epoch 149/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.3164 - mean_absolute_error: 0.3164\n",
      "Epoch 150/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.2991 - mean_absolute_error: 0.2991\n",
      "Epoch 151/300\n",
      "67/67 [==============================] - 0s 5ms/step - loss: 0.3099 - mean_absolute_error: 0.3099\n",
      "Epoch 152/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2857 - mean_absolute_error: 0.2857\n",
      "Epoch 153/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2958 - mean_absolute_error: 0.2958\n",
      "Epoch 154/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2943 - mean_absolute_error: 0.2943\n",
      "Epoch 155/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.2795 - mean_absolute_error: 0.2795\n",
      "Epoch 156/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.2823 - mean_absolute_error: 0.2823\n",
      "Epoch 157/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2889 - mean_absolute_error: 0.2889\n",
      "Epoch 158/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2906 - mean_absolute_error: 0.2906\n",
      "Epoch 159/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.2794 - mean_absolute_error: 0.2794\n",
      "Epoch 160/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2881 - mean_absolute_error: 0.2881\n",
      "Epoch 161/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.3203 - mean_absolute_error: 0.3203\n",
      "Epoch 162/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2897 - mean_absolute_error: 0.2897\n",
      "Epoch 163/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2726 - mean_absolute_error: 0.2726\n",
      "Epoch 164/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2996 - mean_absolute_error: 0.2996\n",
      "Epoch 165/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.3050 - mean_absolute_error: 0.3050\n",
      "Epoch 166/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.3060 - mean_absolute_error: 0.3060\n",
      "Epoch 167/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.3000 - mean_absolute_error: 0.3000\n",
      "Epoch 168/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.3070 - mean_absolute_error: 0.3070\n",
      "Epoch 169/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2689 - mean_absolute_error: 0.2689\n",
      "Epoch 170/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2915 - mean_absolute_error: 0.2915\n",
      "Epoch 171/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2690 - mean_absolute_error: 0.2690\n",
      "Epoch 172/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2626 - mean_absolute_error: 0.2626\n",
      "Epoch 173/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2777 - mean_absolute_error: 0.2777\n",
      "Epoch 174/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2742 - mean_absolute_error: 0.2742\n",
      "Epoch 175/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2496 - mean_absolute_error: 0.2496\n",
      "Epoch 176/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2748 - mean_absolute_error: 0.2748\n",
      "Epoch 177/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2832 - mean_absolute_error: 0.2832\n",
      "Epoch 178/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2905 - mean_absolute_error: 0.2905\n",
      "Epoch 179/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2559 - mean_absolute_error: 0.2559\n",
      "Epoch 180/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2923 - mean_absolute_error: 0.2923\n",
      "Epoch 181/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2706 - mean_absolute_error: 0.2706\n",
      "Epoch 182/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2998 - mean_absolute_error: 0.2998\n",
      "Epoch 183/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2834 - mean_absolute_error: 0.2834\n",
      "Epoch 184/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2754 - mean_absolute_error: 0.2754\n",
      "Epoch 185/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2456 - mean_absolute_error: 0.2456\n",
      "Epoch 186/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2544 - mean_absolute_error: 0.2544\n",
      "Epoch 187/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2530 - mean_absolute_error: 0.2530\n",
      "Epoch 188/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2466 - mean_absolute_error: 0.2466\n",
      "Epoch 189/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2601 - mean_absolute_error: 0.2601\n",
      "Epoch 190/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2733 - mean_absolute_error: 0.2733\n",
      "Epoch 191/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.3085 - mean_absolute_error: 0.3085\n",
      "Epoch 192/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2656 - mean_absolute_error: 0.2656\n",
      "Epoch 193/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2654 - mean_absolute_error: 0.2654\n",
      "Epoch 194/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2481 - mean_absolute_error: 0.2481\n",
      "Epoch 195/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2731 - mean_absolute_error: 0.2731\n",
      "Epoch 196/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2896 - mean_absolute_error: 0.2896\n",
      "Epoch 197/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2490 - mean_absolute_error: 0.2490\n",
      "Epoch 198/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2548 - mean_absolute_error: 0.2548\n",
      "Epoch 199/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2747 - mean_absolute_error: 0.2747\n",
      "Epoch 200/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2661 - mean_absolute_error: 0.2661\n",
      "Epoch 201/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.2540 - mean_absolute_error: 0.2540\n",
      "Epoch 202/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2593 - mean_absolute_error: 0.2593\n",
      "Epoch 203/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2831 - mean_absolute_error: 0.2831\n",
      "Epoch 204/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2685 - mean_absolute_error: 0.2685\n",
      "Epoch 205/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2770 - mean_absolute_error: 0.2770\n",
      "Epoch 206/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.2479 - mean_absolute_error: 0.2479\n",
      "Epoch 207/300\n",
      "67/67 [==============================] - 1s 7ms/step - loss: 0.2585 - mean_absolute_error: 0.2585\n",
      "Epoch 208/300\n",
      "67/67 [==============================] - 1s 10ms/step - loss: 0.2641 - mean_absolute_error: 0.2641\n",
      "Epoch 209/300\n",
      "67/67 [==============================] - 1s 7ms/step - loss: 0.2710 - mean_absolute_error: 0.2710\n",
      "Epoch 210/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.2612 - mean_absolute_error: 0.2612\n",
      "Epoch 211/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2546 - mean_absolute_error: 0.2546\n",
      "Epoch 212/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2661 - mean_absolute_error: 0.2661\n",
      "Epoch 213/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.2520 - mean_absolute_error: 0.2520\n",
      "Epoch 214/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.2498 - mean_absolute_error: 0.2498\n",
      "Epoch 215/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2459 - mean_absolute_error: 0.2459\n",
      "Epoch 216/300\n",
      "67/67 [==============================] - 0s 5ms/step - loss: 0.2524 - mean_absolute_error: 0.2524\n",
      "Epoch 217/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2611 - mean_absolute_error: 0.2611\n",
      "Epoch 218/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.2461 - mean_absolute_error: 0.2461\n",
      "Epoch 219/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2565 - mean_absolute_error: 0.2565\n",
      "Epoch 220/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2614 - mean_absolute_error: 0.2614\n",
      "Epoch 221/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.2611 - mean_absolute_error: 0.2611\n",
      "Epoch 222/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2597 - mean_absolute_error: 0.2597\n",
      "Epoch 223/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.2595 - mean_absolute_error: 0.2595\n",
      "Epoch 224/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.2391 - mean_absolute_error: 0.2391\n",
      "Epoch 225/300\n",
      "67/67 [==============================] - 0s 5ms/step - loss: 0.2447 - mean_absolute_error: 0.2447\n",
      "Epoch 226/300\n",
      "67/67 [==============================] - 0s 5ms/step - loss: 0.2404 - mean_absolute_error: 0.2404\n",
      "Epoch 227/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2440 - mean_absolute_error: 0.2440\n",
      "Epoch 228/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2378 - mean_absolute_error: 0.2378\n",
      "Epoch 229/300\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 0.2495 - mean_absolute_error: 0.2495\n",
      "Epoch 230/300\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.2486 - mean_absolute_error: 0.2486\n",
      "Epoch 231/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.2425 - mean_absolute_error: 0.2425\n",
      "Epoch 232/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2477 - mean_absolute_error: 0.2477\n",
      "Epoch 233/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2405 - mean_absolute_error: 0.2405\n",
      "Epoch 234/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2489 - mean_absolute_error: 0.2489\n",
      "Epoch 235/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2435 - mean_absolute_error: 0.2435\n",
      "Epoch 236/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2358 - mean_absolute_error: 0.2358\n",
      "Epoch 237/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2639 - mean_absolute_error: 0.2639\n",
      "Epoch 238/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.2613 - mean_absolute_error: 0.2613\n",
      "Epoch 239/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2404 - mean_absolute_error: 0.2404\n",
      "Epoch 240/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2339 - mean_absolute_error: 0.2339\n",
      "Epoch 241/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.2292 - mean_absolute_error: 0.2292\n",
      "Epoch 242/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2349 - mean_absolute_error: 0.2349\n",
      "Epoch 243/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2385 - mean_absolute_error: 0.2385\n",
      "Epoch 244/300\n",
      "67/67 [==============================] - 0s 5ms/step - loss: 0.2486 - mean_absolute_error: 0.2486\n",
      "Epoch 245/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.2378 - mean_absolute_error: 0.2378\n",
      "Epoch 246/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2396 - mean_absolute_error: 0.2396\n",
      "Epoch 247/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2304 - mean_absolute_error: 0.2304\n",
      "Epoch 248/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2427 - mean_absolute_error: 0.2427\n",
      "Epoch 249/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2665 - mean_absolute_error: 0.2665\n",
      "Epoch 250/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.2431 - mean_absolute_error: 0.2431\n",
      "Epoch 251/300\n",
      "67/67 [==============================] - 0s 5ms/step - loss: 0.2353 - mean_absolute_error: 0.2353\n",
      "Epoch 252/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2170 - mean_absolute_error: 0.2170\n",
      "Epoch 253/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2306 - mean_absolute_error: 0.2306\n",
      "Epoch 254/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2253 - mean_absolute_error: 0.2253\n",
      "Epoch 255/300\n",
      "67/67 [==============================] - 0s 5ms/step - loss: 0.2312 - mean_absolute_error: 0.2312\n",
      "Epoch 256/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.2326 - mean_absolute_error: 0.2326\n",
      "Epoch 257/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2236 - mean_absolute_error: 0.2236\n",
      "Epoch 258/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.2208 - mean_absolute_error: 0.2208\n",
      "Epoch 259/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2301 - mean_absolute_error: 0.2301\n",
      "Epoch 260/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2534 - mean_absolute_error: 0.2534\n",
      "Epoch 261/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2433 - mean_absolute_error: 0.2433\n",
      "Epoch 262/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2456 - mean_absolute_error: 0.2456\n",
      "Epoch 263/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2380 - mean_absolute_error: 0.2380\n",
      "Epoch 264/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2331 - mean_absolute_error: 0.2331\n",
      "Epoch 265/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2281 - mean_absolute_error: 0.2281\n",
      "Epoch 266/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2387 - mean_absolute_error: 0.2387\n",
      "Epoch 267/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2512 - mean_absolute_error: 0.2512\n",
      "Epoch 268/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2383 - mean_absolute_error: 0.2383\n",
      "Epoch 269/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2409 - mean_absolute_error: 0.2409\n",
      "Epoch 270/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2378 - mean_absolute_error: 0.2378\n",
      "Epoch 271/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2322 - mean_absolute_error: 0.2322\n",
      "Epoch 272/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2254 - mean_absolute_error: 0.2254\n",
      "Epoch 273/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2223 - mean_absolute_error: 0.2223\n",
      "Epoch 274/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2314 - mean_absolute_error: 0.2314\n",
      "Epoch 275/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2257 - mean_absolute_error: 0.2257\n",
      "Epoch 276/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2175 - mean_absolute_error: 0.2175\n",
      "Epoch 277/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2181 - mean_absolute_error: 0.2181\n",
      "Epoch 278/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2230 - mean_absolute_error: 0.2230\n",
      "Epoch 279/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2338 - mean_absolute_error: 0.2338\n",
      "Epoch 280/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2378 - mean_absolute_error: 0.2378\n",
      "Epoch 281/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2400 - mean_absolute_error: 0.2400\n",
      "Epoch 282/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2181 - mean_absolute_error: 0.2181\n",
      "Epoch 283/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2170 - mean_absolute_error: 0.2170\n",
      "Epoch 284/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2376 - mean_absolute_error: 0.2376\n",
      "Epoch 285/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2379 - mean_absolute_error: 0.2379\n",
      "Epoch 286/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2300 - mean_absolute_error: 0.2300\n",
      "Epoch 287/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2241 - mean_absolute_error: 0.2241\n",
      "Epoch 288/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2445 - mean_absolute_error: 0.2445\n",
      "Epoch 289/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2254 - mean_absolute_error: 0.2254\n",
      "Epoch 290/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2385 - mean_absolute_error: 0.2385\n",
      "Epoch 291/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2267 - mean_absolute_error: 0.2267\n",
      "Epoch 292/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2134 - mean_absolute_error: 0.2134\n",
      "Epoch 293/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2403 - mean_absolute_error: 0.2403\n",
      "Epoch 294/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2295 - mean_absolute_error: 0.2295\n",
      "Epoch 295/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2287 - mean_absolute_error: 0.2287\n",
      "Epoch 296/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2304 - mean_absolute_error: 0.2304\n",
      "Epoch 297/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2161 - mean_absolute_error: 0.2161\n",
      "Epoch 298/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.2241 - mean_absolute_error: 0.2241\n",
      "Epoch 299/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.2109 - mean_absolute_error: 0.2109\n",
      "Epoch 300/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2225 - mean_absolute_error: 0.2225\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled,y_train,epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c394d261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 - 0s - loss: 1.8309 - mean_absolute_error: 1.8309 - 273ms/epoch - 9ms/step\n",
      "Loss: 1.8309117555618286, Accuracy: 1.8309117555618286\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "65045f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = nn.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4e18f381",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.076908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.660000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.746509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.942185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.952025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>906</th>\n",
       "      <td>16.687016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907</th>\n",
       "      <td>16.794416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>908</th>\n",
       "      <td>17.309942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>909</th>\n",
       "      <td>18.110512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910</th>\n",
       "      <td>18.315954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>911 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0\n",
       "0     2.076908\n",
       "1     2.660000\n",
       "2     2.746509\n",
       "3     2.942185\n",
       "4     2.952025\n",
       "..         ...\n",
       "906  16.687016\n",
       "907  16.794416\n",
       "908  17.309942\n",
       "909  18.110512\n",
       "910  18.315954\n",
       "\n",
       "[911 rows x 1 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "442b1b05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.811701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.951987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.173124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.184300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.410551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>906</th>\n",
       "      <td>20.666338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907</th>\n",
       "      <td>21.710432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>908</th>\n",
       "      <td>23.205549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>909</th>\n",
       "      <td>25.529351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910</th>\n",
       "      <td>38.010657</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>911 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0\n",
       "0     1.811701\n",
       "1     1.951987\n",
       "2     2.173124\n",
       "3     2.184300\n",
       "4     2.410551\n",
       "..         ...\n",
       "906  20.666338\n",
       "907  21.710432\n",
       "908  23.205549\n",
       "909  25.529351\n",
       "910  38.010657\n",
       "\n",
       "[911 rows x 1 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "96f4e93e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'0'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/c4/4wwc7xj11_d_3x_fxkhmrtnh0000gn/T/ipykernel_30944/3828466770.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mactual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mactual\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'0'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/mlenv/lib/python3.7/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mlenv/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36msort_values\u001b[0;34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[0m\n\u001b[1;32m   6257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6258\u001b[0m             \u001b[0mby\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6259\u001b[0;31m             \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6261\u001b[0m             \u001b[0;31m# need to rewrap column in Series to apply key function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mlenv/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_label_or_level_values\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1777\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1778\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1779\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1780\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1781\u001b[0m         \u001b[0;31m# Check for duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '0'"
     ]
    }
   ],
   "source": [
    "actual = pd.DataFrame(y_test)\n",
    "actual.sort_values(by = ['0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b5d65c2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.140968</td>\n",
       "      <td>7.767897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.098922</td>\n",
       "      <td>7.887645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.709403</td>\n",
       "      <td>10.425520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.180491</td>\n",
       "      <td>7.425735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.790214</td>\n",
       "      <td>8.993594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>906</th>\n",
       "      <td>12.191149</td>\n",
       "      <td>11.108071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907</th>\n",
       "      <td>3.811820</td>\n",
       "      <td>3.549889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>908</th>\n",
       "      <td>8.021267</td>\n",
       "      <td>10.344869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>909</th>\n",
       "      <td>9.246785</td>\n",
       "      <td>11.627671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910</th>\n",
       "      <td>9.897234</td>\n",
       "      <td>7.672501</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>911 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Actual       Pred\n",
       "0     8.140968   7.767897\n",
       "1     8.098922   7.887645\n",
       "2    10.709403  10.425520\n",
       "3     7.180491   7.425735\n",
       "4     3.790214   8.993594\n",
       "..         ...        ...\n",
       "906  12.191149  11.108071\n",
       "907   3.811820   3.549889\n",
       "908   8.021267  10.344869\n",
       "909   9.246785  11.627671\n",
       "910   9.897234   7.672501\n",
       "\n",
       "[911 rows x 2 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge predictions and actuals into dataframe\n",
    "results = actual.merge(pred, how = 'inner', left_index=True, right_index=True)\n",
    "results = results.rename(columns = {'0_x':'Actual', '0_y':'Pred'})\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2f03e8ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Pred</th>\n",
       "      <th>error</th>\n",
       "      <th>abs_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.140968</td>\n",
       "      <td>7.767897</td>\n",
       "      <td>0.373071</td>\n",
       "      <td>0.373071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.098922</td>\n",
       "      <td>7.887645</td>\n",
       "      <td>0.211278</td>\n",
       "      <td>0.211278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.709403</td>\n",
       "      <td>10.425520</td>\n",
       "      <td>0.283883</td>\n",
       "      <td>0.283883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.180491</td>\n",
       "      <td>7.425735</td>\n",
       "      <td>-0.245243</td>\n",
       "      <td>0.245243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.790214</td>\n",
       "      <td>8.993594</td>\n",
       "      <td>-5.203380</td>\n",
       "      <td>5.203380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>906</th>\n",
       "      <td>12.191149</td>\n",
       "      <td>11.108071</td>\n",
       "      <td>1.083077</td>\n",
       "      <td>1.083077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907</th>\n",
       "      <td>3.811820</td>\n",
       "      <td>3.549889</td>\n",
       "      <td>0.261931</td>\n",
       "      <td>0.261931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>908</th>\n",
       "      <td>8.021267</td>\n",
       "      <td>10.344869</td>\n",
       "      <td>-2.323602</td>\n",
       "      <td>2.323602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>909</th>\n",
       "      <td>9.246785</td>\n",
       "      <td>11.627671</td>\n",
       "      <td>-2.380886</td>\n",
       "      <td>2.380886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910</th>\n",
       "      <td>9.897234</td>\n",
       "      <td>7.672501</td>\n",
       "      <td>2.224733</td>\n",
       "      <td>2.224733</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>911 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Actual       Pred     error  abs_error\n",
       "0     8.140968   7.767897  0.373071   0.373071\n",
       "1     8.098922   7.887645  0.211278   0.211278\n",
       "2    10.709403  10.425520  0.283883   0.283883\n",
       "3     7.180491   7.425735 -0.245243   0.245243\n",
       "4     3.790214   8.993594 -5.203380   5.203380\n",
       "..         ...        ...       ...        ...\n",
       "906  12.191149  11.108071  1.083077   1.083077\n",
       "907   3.811820   3.549889  0.261931   0.261931\n",
       "908   8.021267  10.344869 -2.323602   2.323602\n",
       "909   9.246785  11.627671 -2.380886   2.380886\n",
       "910   9.897234   7.672501  2.224733   2.224733\n",
       "\n",
       "[911 rows x 4 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check how big the errors are on each prediction\n",
    "results['error'] = results['Actual']-results['Pred']\n",
    "results['abs_error'] = abs(results['error'])\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "98f83f3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f81cfc3c110>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot the errors\n",
    "plt.scatter(results.index,results['error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a751ba9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    911.000000\n",
       "mean       0.031424\n",
       "std        2.542407\n",
       "min      -11.144718\n",
       "25%       -1.367507\n",
       "50%       -0.034947\n",
       "75%        1.465961\n",
       "max       25.879080\n",
       "Name: error, dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# explore errors\n",
    "results['error'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4be18a95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    911.000000\n",
       "mean       1.830912\n",
       "std        1.763208\n",
       "min        0.000082\n",
       "25%        0.653523\n",
       "50%        1.393163\n",
       "75%        2.535832\n",
       "max       25.879080\n",
       "Name: abs_error, dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#explor absolute error\n",
    "results['abs_error'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4044bf68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AREA_SQMI</th>\n",
       "      <th>EP_POV</th>\n",
       "      <th>EP_UNEMP</th>\n",
       "      <th>EP_PCI</th>\n",
       "      <th>EP_NOHSDP</th>\n",
       "      <th>EP_AGE65</th>\n",
       "      <th>EP_AGE17</th>\n",
       "      <th>EP_DISABL</th>\n",
       "      <th>EP_SNGPNT</th>\n",
       "      <th>EP_MINRTY</th>\n",
       "      <th>...</th>\n",
       "      <th>Hopefulness</th>\n",
       "      <th>Income Per Capita</th>\n",
       "      <th>Neuroticism</th>\n",
       "      <th>Openness</th>\n",
       "      <th>Religiosity</th>\n",
       "      <th>Risk Taking</th>\n",
       "      <th>Selflessness</th>\n",
       "      <th>Tolerance</th>\n",
       "      <th>Work Ethic</th>\n",
       "      <th>E_TOTPOP</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FIPS</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53017</th>\n",
       "      <td>1819.262375</td>\n",
       "      <td>13.3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>28579.0</td>\n",
       "      <td>18.2</td>\n",
       "      <td>16.6</td>\n",
       "      <td>26.2</td>\n",
       "      <td>19.2</td>\n",
       "      <td>10.6</td>\n",
       "      <td>35.5</td>\n",
       "      <td>...</td>\n",
       "      <td>84.640968</td>\n",
       "      <td>23966.0</td>\n",
       "      <td>76.211164</td>\n",
       "      <td>79.108451</td>\n",
       "      <td>73.885947</td>\n",
       "      <td>69.093608</td>\n",
       "      <td>78.905040</td>\n",
       "      <td>69.333062</td>\n",
       "      <td>68.743486</td>\n",
       "      <td>41371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17077</th>\n",
       "      <td>584.071630</td>\n",
       "      <td>27.5</td>\n",
       "      <td>9.4</td>\n",
       "      <td>24521.0</td>\n",
       "      <td>7.8</td>\n",
       "      <td>14.3</td>\n",
       "      <td>18.2</td>\n",
       "      <td>14.0</td>\n",
       "      <td>9.2</td>\n",
       "      <td>25.8</td>\n",
       "      <td>...</td>\n",
       "      <td>82.553246</td>\n",
       "      <td>21948.0</td>\n",
       "      <td>77.135561</td>\n",
       "      <td>83.016931</td>\n",
       "      <td>69.116337</td>\n",
       "      <td>70.829460</td>\n",
       "      <td>77.253521</td>\n",
       "      <td>70.307353</td>\n",
       "      <td>71.942245</td>\n",
       "      <td>58551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34013</th>\n",
       "      <td>126.084488</td>\n",
       "      <td>16.4</td>\n",
       "      <td>9.2</td>\n",
       "      <td>37141.0</td>\n",
       "      <td>14.3</td>\n",
       "      <td>13.1</td>\n",
       "      <td>23.8</td>\n",
       "      <td>11.6</td>\n",
       "      <td>12.7</td>\n",
       "      <td>69.2</td>\n",
       "      <td>...</td>\n",
       "      <td>82.552870</td>\n",
       "      <td>33482.0</td>\n",
       "      <td>77.788587</td>\n",
       "      <td>78.995606</td>\n",
       "      <td>53.303232</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>85.030864</td>\n",
       "      <td>64.848485</td>\n",
       "      <td>64.236111</td>\n",
       "      <td>793555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26151</th>\n",
       "      <td>962.569845</td>\n",
       "      <td>15.6</td>\n",
       "      <td>7.0</td>\n",
       "      <td>24835.0</td>\n",
       "      <td>12.1</td>\n",
       "      <td>20.5</td>\n",
       "      <td>21.8</td>\n",
       "      <td>17.8</td>\n",
       "      <td>7.6</td>\n",
       "      <td>5.9</td>\n",
       "      <td>...</td>\n",
       "      <td>83.973137</td>\n",
       "      <td>22510.0</td>\n",
       "      <td>79.529463</td>\n",
       "      <td>78.540303</td>\n",
       "      <td>73.047368</td>\n",
       "      <td>70.188787</td>\n",
       "      <td>76.644722</td>\n",
       "      <td>66.428418</td>\n",
       "      <td>70.478950</td>\n",
       "      <td>41376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41071</th>\n",
       "      <td>715.898432</td>\n",
       "      <td>13.7</td>\n",
       "      <td>5.4</td>\n",
       "      <td>29141.0</td>\n",
       "      <td>11.7</td>\n",
       "      <td>16.3</td>\n",
       "      <td>22.8</td>\n",
       "      <td>15.4</td>\n",
       "      <td>8.5</td>\n",
       "      <td>22.7</td>\n",
       "      <td>...</td>\n",
       "      <td>85.166660</td>\n",
       "      <td>26523.0</td>\n",
       "      <td>76.136032</td>\n",
       "      <td>79.542651</td>\n",
       "      <td>65.926047</td>\n",
       "      <td>93.333333</td>\n",
       "      <td>80.781893</td>\n",
       "      <td>74.194444</td>\n",
       "      <td>70.666667</td>\n",
       "      <td>103820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12123</th>\n",
       "      <td>1043.317350</td>\n",
       "      <td>19.8</td>\n",
       "      <td>6.2</td>\n",
       "      <td>16919.0</td>\n",
       "      <td>22.6</td>\n",
       "      <td>19.1</td>\n",
       "      <td>19.2</td>\n",
       "      <td>22.7</td>\n",
       "      <td>6.6</td>\n",
       "      <td>28.0</td>\n",
       "      <td>...</td>\n",
       "      <td>82.134520</td>\n",
       "      <td>16081.0</td>\n",
       "      <td>80.324690</td>\n",
       "      <td>77.229458</td>\n",
       "      <td>71.810513</td>\n",
       "      <td>77.831058</td>\n",
       "      <td>75.791195</td>\n",
       "      <td>67.140030</td>\n",
       "      <td>66.437333</td>\n",
       "      <td>22098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36031</th>\n",
       "      <td>1794.117241</td>\n",
       "      <td>9.5</td>\n",
       "      <td>5.8</td>\n",
       "      <td>30273.0</td>\n",
       "      <td>8.9</td>\n",
       "      <td>22.0</td>\n",
       "      <td>16.8</td>\n",
       "      <td>16.8</td>\n",
       "      <td>8.3</td>\n",
       "      <td>7.9</td>\n",
       "      <td>...</td>\n",
       "      <td>82.787801</td>\n",
       "      <td>28155.0</td>\n",
       "      <td>78.747850</td>\n",
       "      <td>81.263854</td>\n",
       "      <td>67.718872</td>\n",
       "      <td>73.138611</td>\n",
       "      <td>75.553172</td>\n",
       "      <td>66.752370</td>\n",
       "      <td>76.085473</td>\n",
       "      <td>37751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16071</th>\n",
       "      <td>1198.950669</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>21575.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>29.3</td>\n",
       "      <td>17.4</td>\n",
       "      <td>5.2</td>\n",
       "      <td>6.6</td>\n",
       "      <td>...</td>\n",
       "      <td>84.640763</td>\n",
       "      <td>19073.0</td>\n",
       "      <td>72.839578</td>\n",
       "      <td>80.126388</td>\n",
       "      <td>65.079780</td>\n",
       "      <td>78.468896</td>\n",
       "      <td>78.338268</td>\n",
       "      <td>70.308700</td>\n",
       "      <td>67.667335</td>\n",
       "      <td>4326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18133</th>\n",
       "      <td>480.537102</td>\n",
       "      <td>12.4</td>\n",
       "      <td>4.2</td>\n",
       "      <td>24627.0</td>\n",
       "      <td>10.8</td>\n",
       "      <td>15.8</td>\n",
       "      <td>19.3</td>\n",
       "      <td>14.1</td>\n",
       "      <td>8.5</td>\n",
       "      <td>8.2</td>\n",
       "      <td>...</td>\n",
       "      <td>84.559589</td>\n",
       "      <td>23040.0</td>\n",
       "      <td>78.315903</td>\n",
       "      <td>79.267717</td>\n",
       "      <td>69.046764</td>\n",
       "      <td>67.590378</td>\n",
       "      <td>74.308291</td>\n",
       "      <td>69.929567</td>\n",
       "      <td>71.732611</td>\n",
       "      <td>37559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18011</th>\n",
       "      <td>422.911774</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.5</td>\n",
       "      <td>44712.0</td>\n",
       "      <td>6.4</td>\n",
       "      <td>12.6</td>\n",
       "      <td>26.8</td>\n",
       "      <td>9.9</td>\n",
       "      <td>7.5</td>\n",
       "      <td>8.9</td>\n",
       "      <td>...</td>\n",
       "      <td>82.797170</td>\n",
       "      <td>40487.0</td>\n",
       "      <td>77.250389</td>\n",
       "      <td>79.376135</td>\n",
       "      <td>65.263677</td>\n",
       "      <td>74.350709</td>\n",
       "      <td>78.011269</td>\n",
       "      <td>72.177977</td>\n",
       "      <td>71.741856</td>\n",
       "      <td>64321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>911 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         AREA_SQMI  EP_POV  EP_UNEMP   EP_PCI  EP_NOHSDP  EP_AGE65  EP_AGE17  \\\n",
       "FIPS                                                                           \n",
       "53017  1819.262375    13.3       4.0  28579.0       18.2      16.6      26.2   \n",
       "17077   584.071630    27.5       9.4  24521.0        7.8      14.3      18.2   \n",
       "34013   126.084488    16.4       9.2  37141.0       14.3      13.1      23.8   \n",
       "26151   962.569845    15.6       7.0  24835.0       12.1      20.5      21.8   \n",
       "41071   715.898432    13.7       5.4  29141.0       11.7      16.3      22.8   \n",
       "...            ...     ...       ...      ...        ...       ...       ...   \n",
       "12123  1043.317350    19.8       6.2  16919.0       22.6      19.1      19.2   \n",
       "36031  1794.117241     9.5       5.8  30273.0        8.9      22.0      16.8   \n",
       "16071  1198.950669    13.0       5.1  21575.0        9.0      19.2      29.3   \n",
       "18133   480.537102    12.4       4.2  24627.0       10.8      15.8      19.3   \n",
       "18011   422.911774     5.4       2.5  44712.0        6.4      12.6      26.8   \n",
       "\n",
       "       EP_DISABL  EP_SNGPNT  EP_MINRTY  ...  Hopefulness  Income Per Capita  \\\n",
       "FIPS                                    ...                                   \n",
       "53017       19.2       10.6       35.5  ...    84.640968            23966.0   \n",
       "17077       14.0        9.2       25.8  ...    82.553246            21948.0   \n",
       "34013       11.6       12.7       69.2  ...    82.552870            33482.0   \n",
       "26151       17.8        7.6        5.9  ...    83.973137            22510.0   \n",
       "41071       15.4        8.5       22.7  ...    85.166660            26523.0   \n",
       "...          ...        ...        ...  ...          ...                ...   \n",
       "12123       22.7        6.6       28.0  ...    82.134520            16081.0   \n",
       "36031       16.8        8.3        7.9  ...    82.787801            28155.0   \n",
       "16071       17.4        5.2        6.6  ...    84.640763            19073.0   \n",
       "18133       14.1        8.5        8.2  ...    84.559589            23040.0   \n",
       "18011        9.9        7.5        8.9  ...    82.797170            40487.0   \n",
       "\n",
       "       Neuroticism   Openness  Religiosity  Risk Taking  Selflessness  \\\n",
       "FIPS                                                                    \n",
       "53017    76.211164  79.108451    73.885947    69.093608     78.905040   \n",
       "17077    77.135561  83.016931    69.116337    70.829460     77.253521   \n",
       "34013    77.788587  78.995606    53.303232    80.000000     85.030864   \n",
       "26151    79.529463  78.540303    73.047368    70.188787     76.644722   \n",
       "41071    76.136032  79.542651    65.926047    93.333333     80.781893   \n",
       "...            ...        ...          ...          ...           ...   \n",
       "12123    80.324690  77.229458    71.810513    77.831058     75.791195   \n",
       "36031    78.747850  81.263854    67.718872    73.138611     75.553172   \n",
       "16071    72.839578  80.126388    65.079780    78.468896     78.338268   \n",
       "18133    78.315903  79.267717    69.046764    67.590378     74.308291   \n",
       "18011    77.250389  79.376135    65.263677    74.350709     78.011269   \n",
       "\n",
       "       Tolerance  Work Ethic  E_TOTPOP  \n",
       "FIPS                                    \n",
       "53017  69.333062   68.743486     41371  \n",
       "17077  70.307353   71.942245     58551  \n",
       "34013  64.848485   64.236111    793555  \n",
       "26151  66.428418   70.478950     41376  \n",
       "41071  74.194444   70.666667    103820  \n",
       "...          ...         ...       ...  \n",
       "12123  67.140030   66.437333     22098  \n",
       "36031  66.752370   76.085473     37751  \n",
       "16071  70.308700   67.667335      4326  \n",
       "18133  69.929567   71.732611     37559  \n",
       "18011  72.177977   71.741856     64321  \n",
       "\n",
       "[911 rows x 63 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66910f0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
