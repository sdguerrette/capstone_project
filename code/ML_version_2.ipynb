{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c130683c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dependencies\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c84493f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIPS</th>\n",
       "      <th>3/31/21</th>\n",
       "      <th>AREA_SQMI</th>\n",
       "      <th>E_TOTPOP</th>\n",
       "      <th>E_HU</th>\n",
       "      <th>E_HH</th>\n",
       "      <th>E_POV</th>\n",
       "      <th>E_UNEMP</th>\n",
       "      <th>E_PCI</th>\n",
       "      <th>E_NOHSDP</th>\n",
       "      <th>...</th>\n",
       "      <th>Hopefulness</th>\n",
       "      <th>Income Per Capita</th>\n",
       "      <th>Neuroticism</th>\n",
       "      <th>Openness</th>\n",
       "      <th>Religiosity</th>\n",
       "      <th>Risk Taking</th>\n",
       "      <th>Selflessness</th>\n",
       "      <th>Tolerance</th>\n",
       "      <th>Work Ethic</th>\n",
       "      <th>dem_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>6589</td>\n",
       "      <td>594.443459</td>\n",
       "      <td>55200.0</td>\n",
       "      <td>23315.0</td>\n",
       "      <td>21115.0</td>\n",
       "      <td>8422.0</td>\n",
       "      <td>1065.0</td>\n",
       "      <td>29372.0</td>\n",
       "      <td>4204.0</td>\n",
       "      <td>...</td>\n",
       "      <td>91.163142</td>\n",
       "      <td>26168.0</td>\n",
       "      <td>77.925476</td>\n",
       "      <td>78.222354</td>\n",
       "      <td>91.106719</td>\n",
       "      <td>53.333333</td>\n",
       "      <td>82.142857</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>60.380952</td>\n",
       "      <td>27.018365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1003</td>\n",
       "      <td>20505</td>\n",
       "      <td>1589.793007</td>\n",
       "      <td>208107.0</td>\n",
       "      <td>111945.0</td>\n",
       "      <td>78622.0</td>\n",
       "      <td>21653.0</td>\n",
       "      <td>4343.0</td>\n",
       "      <td>31203.0</td>\n",
       "      <td>14310.0</td>\n",
       "      <td>...</td>\n",
       "      <td>82.484017</td>\n",
       "      <td>28069.0</td>\n",
       "      <td>77.232120</td>\n",
       "      <td>80.086368</td>\n",
       "      <td>71.771566</td>\n",
       "      <td>67.272980</td>\n",
       "      <td>75.586018</td>\n",
       "      <td>66.983549</td>\n",
       "      <td>70.972246</td>\n",
       "      <td>22.409030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1005</td>\n",
       "      <td>2227</td>\n",
       "      <td>885.001636</td>\n",
       "      <td>25782.0</td>\n",
       "      <td>11937.0</td>\n",
       "      <td>9186.0</td>\n",
       "      <td>6597.0</td>\n",
       "      <td>918.0</td>\n",
       "      <td>18461.0</td>\n",
       "      <td>4901.0</td>\n",
       "      <td>...</td>\n",
       "      <td>61.927181</td>\n",
       "      <td>17249.0</td>\n",
       "      <td>80.375206</td>\n",
       "      <td>78.783778</td>\n",
       "      <td>73.657368</td>\n",
       "      <td>76.066481</td>\n",
       "      <td>78.753019</td>\n",
       "      <td>65.170377</td>\n",
       "      <td>68.704105</td>\n",
       "      <td>45.788173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1007</td>\n",
       "      <td>2542</td>\n",
       "      <td>622.461089</td>\n",
       "      <td>22527.0</td>\n",
       "      <td>9161.0</td>\n",
       "      <td>6840.0</td>\n",
       "      <td>2863.0</td>\n",
       "      <td>658.0</td>\n",
       "      <td>20199.0</td>\n",
       "      <td>2650.0</td>\n",
       "      <td>...</td>\n",
       "      <td>85.258871</td>\n",
       "      <td>18988.0</td>\n",
       "      <td>80.813736</td>\n",
       "      <td>77.837027</td>\n",
       "      <td>69.974652</td>\n",
       "      <td>75.136154</td>\n",
       "      <td>76.929754</td>\n",
       "      <td>69.859503</td>\n",
       "      <td>67.931677</td>\n",
       "      <td>20.698280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1009</td>\n",
       "      <td>6444</td>\n",
       "      <td>644.830460</td>\n",
       "      <td>57645.0</td>\n",
       "      <td>24222.0</td>\n",
       "      <td>20600.0</td>\n",
       "      <td>8220.0</td>\n",
       "      <td>909.0</td>\n",
       "      <td>22656.0</td>\n",
       "      <td>7861.0</td>\n",
       "      <td>...</td>\n",
       "      <td>79.492703</td>\n",
       "      <td>21033.0</td>\n",
       "      <td>78.764620</td>\n",
       "      <td>78.193105</td>\n",
       "      <td>92.045455</td>\n",
       "      <td>57.603815</td>\n",
       "      <td>79.307632</td>\n",
       "      <td>64.953288</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>9.569378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3053</th>\n",
       "      <td>56037</td>\n",
       "      <td>4022</td>\n",
       "      <td>10426.975725</td>\n",
       "      <td>44117.0</td>\n",
       "      <td>19628.0</td>\n",
       "      <td>15871.0</td>\n",
       "      <td>5237.0</td>\n",
       "      <td>1213.0</td>\n",
       "      <td>32624.0</td>\n",
       "      <td>2549.0</td>\n",
       "      <td>...</td>\n",
       "      <td>82.403142</td>\n",
       "      <td>30945.0</td>\n",
       "      <td>79.384759</td>\n",
       "      <td>79.347081</td>\n",
       "      <td>68.147062</td>\n",
       "      <td>73.938691</td>\n",
       "      <td>76.390464</td>\n",
       "      <td>67.420658</td>\n",
       "      <td>70.956334</td>\n",
       "      <td>22.894957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3054</th>\n",
       "      <td>56039</td>\n",
       "      <td>3609</td>\n",
       "      <td>3996.844622</td>\n",
       "      <td>23059.0</td>\n",
       "      <td>13680.0</td>\n",
       "      <td>9158.0</td>\n",
       "      <td>1619.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>53703.0</td>\n",
       "      <td>958.0</td>\n",
       "      <td>...</td>\n",
       "      <td>84.036899</td>\n",
       "      <td>46499.0</td>\n",
       "      <td>71.547359</td>\n",
       "      <td>80.522872</td>\n",
       "      <td>65.399695</td>\n",
       "      <td>79.598153</td>\n",
       "      <td>79.698193</td>\n",
       "      <td>70.877600</td>\n",
       "      <td>70.938645</td>\n",
       "      <td>66.599040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3055</th>\n",
       "      <td>56041</td>\n",
       "      <td>2128</td>\n",
       "      <td>2081.719807</td>\n",
       "      <td>20609.0</td>\n",
       "      <td>8972.0</td>\n",
       "      <td>7735.0</td>\n",
       "      <td>2552.0</td>\n",
       "      <td>614.0</td>\n",
       "      <td>27009.0</td>\n",
       "      <td>934.0</td>\n",
       "      <td>...</td>\n",
       "      <td>84.089095</td>\n",
       "      <td>25636.0</td>\n",
       "      <td>78.771570</td>\n",
       "      <td>77.859042</td>\n",
       "      <td>67.603416</td>\n",
       "      <td>69.705859</td>\n",
       "      <td>73.332067</td>\n",
       "      <td>67.404487</td>\n",
       "      <td>69.299391</td>\n",
       "      <td>16.819960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3056</th>\n",
       "      <td>56043</td>\n",
       "      <td>891</td>\n",
       "      <td>2238.672972</td>\n",
       "      <td>8129.0</td>\n",
       "      <td>3868.0</td>\n",
       "      <td>3422.0</td>\n",
       "      <td>984.0</td>\n",
       "      <td>253.0</td>\n",
       "      <td>27556.0</td>\n",
       "      <td>590.0</td>\n",
       "      <td>...</td>\n",
       "      <td>87.485019</td>\n",
       "      <td>26325.0</td>\n",
       "      <td>76.249370</td>\n",
       "      <td>77.658224</td>\n",
       "      <td>67.412774</td>\n",
       "      <td>82.820701</td>\n",
       "      <td>78.925326</td>\n",
       "      <td>74.628788</td>\n",
       "      <td>70.050103</td>\n",
       "      <td>16.145833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3057</th>\n",
       "      <td>56045</td>\n",
       "      <td>633</td>\n",
       "      <td>2398.003891</td>\n",
       "      <td>7100.0</td>\n",
       "      <td>3565.0</td>\n",
       "      <td>3062.0</td>\n",
       "      <td>1171.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>29152.0</td>\n",
       "      <td>389.0</td>\n",
       "      <td>...</td>\n",
       "      <td>80.975991</td>\n",
       "      <td>29493.0</td>\n",
       "      <td>79.961075</td>\n",
       "      <td>76.977099</td>\n",
       "      <td>71.535519</td>\n",
       "      <td>75.406846</td>\n",
       "      <td>76.730879</td>\n",
       "      <td>68.422269</td>\n",
       "      <td>69.413532</td>\n",
       "      <td>10.112360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3058 rows × 104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       FIPS  3/31/21     AREA_SQMI  E_TOTPOP      E_HU     E_HH    E_POV  \\\n",
       "0      1001     6589    594.443459   55200.0   23315.0  21115.0   8422.0   \n",
       "1      1003    20505   1589.793007  208107.0  111945.0  78622.0  21653.0   \n",
       "2      1005     2227    885.001636   25782.0   11937.0   9186.0   6597.0   \n",
       "3      1007     2542    622.461089   22527.0    9161.0   6840.0   2863.0   \n",
       "4      1009     6444    644.830460   57645.0   24222.0  20600.0   8220.0   \n",
       "...     ...      ...           ...       ...       ...      ...      ...   \n",
       "3053  56037     4022  10426.975725   44117.0   19628.0  15871.0   5237.0   \n",
       "3054  56039     3609   3996.844622   23059.0   13680.0   9158.0   1619.0   \n",
       "3055  56041     2128   2081.719807   20609.0    8972.0   7735.0   2552.0   \n",
       "3056  56043      891   2238.672972    8129.0    3868.0   3422.0    984.0   \n",
       "3057  56045      633   2398.003891    7100.0    3565.0   3062.0   1171.0   \n",
       "\n",
       "      E_UNEMP    E_PCI  E_NOHSDP  ...  Hopefulness  Income Per Capita  \\\n",
       "0      1065.0  29372.0    4204.0  ...    91.163142            26168.0   \n",
       "1      4343.0  31203.0   14310.0  ...    82.484017            28069.0   \n",
       "2       918.0  18461.0    4901.0  ...    61.927181            17249.0   \n",
       "3       658.0  20199.0    2650.0  ...    85.258871            18988.0   \n",
       "4       909.0  22656.0    7861.0  ...    79.492703            21033.0   \n",
       "...       ...      ...       ...  ...          ...                ...   \n",
       "3053   1213.0  32624.0    2549.0  ...    82.403142            30945.0   \n",
       "3054    210.0  53703.0     958.0  ...    84.036899            46499.0   \n",
       "3055    614.0  27009.0     934.0  ...    84.089095            25636.0   \n",
       "3056    253.0  27556.0     590.0  ...    87.485019            26325.0   \n",
       "3057    117.0  29152.0     389.0  ...    80.975991            29493.0   \n",
       "\n",
       "      Neuroticism   Openness  Religiosity  Risk Taking  Selflessness  \\\n",
       "0       77.925476  78.222354    91.106719    53.333333     82.142857   \n",
       "1       77.232120  80.086368    71.771566    67.272980     75.586018   \n",
       "2       80.375206  78.783778    73.657368    76.066481     78.753019   \n",
       "3       80.813736  77.837027    69.974652    75.136154     76.929754   \n",
       "4       78.764620  78.193105    92.045455    57.603815     79.307632   \n",
       "...           ...        ...          ...          ...           ...   \n",
       "3053    79.384759  79.347081    68.147062    73.938691     76.390464   \n",
       "3054    71.547359  80.522872    65.399695    79.598153     79.698193   \n",
       "3055    78.771570  77.859042    67.603416    69.705859     73.332067   \n",
       "3056    76.249370  77.658224    67.412774    82.820701     78.925326   \n",
       "3057    79.961075  76.977099    71.535519    75.406846     76.730879   \n",
       "\n",
       "      Tolerance  Work Ethic    dem_pct  \n",
       "0     70.000000   60.380952  27.018365  \n",
       "1     66.983549   70.972246  22.409030  \n",
       "2     65.170377   68.704105  45.788173  \n",
       "3     69.859503   67.931677  20.698280  \n",
       "4     64.953288   76.000000   9.569378  \n",
       "...         ...         ...        ...  \n",
       "3053  67.420658   70.956334  22.894957  \n",
       "3054  70.877600   70.938645  66.599040  \n",
       "3055  67.404487   69.299391  16.819960  \n",
       "3056  74.628788   70.050103  16.145833  \n",
       "3057  68.422269   69.413532  10.112360  \n",
       "\n",
       "[3058 rows x 104 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read in merged and cleaned data\n",
    "df = pd.read_csv('../modified_data/pol_svi_sc_merged.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3182e6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set index to FIPS\n",
    "df = df.set_index(df['FIPS'])\n",
    "df= df.drop('FIPS', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77087806",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename target column\n",
    "df = df.rename(columns={'3/31/21':'first_year_cases'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b64c46df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FIPS\n",
       "1001    11.936594\n",
       "1003     9.853104\n",
       "1005     8.637809\n",
       "1007    11.284237\n",
       "1009    11.178767\n",
       "Name: case_pct, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create variable for case% for each counties population\n",
    "df['case_pct'] = df['first_year_cases']/df['E_TOTPOP']*100\n",
    "df['case_pct'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78c3a477",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    3058.000000\n",
       "mean        9.426600\n",
       "std         3.045809\n",
       "min         0.000000\n",
       "25%         7.713422\n",
       "50%         9.466675\n",
       "75%        11.176131\n",
       "max        38.010657\n",
       "Name: case_pct, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['case_pct'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3cd247c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FIPS\n",
       "1001      low\n",
       "1003      low\n",
       "1005      low\n",
       "1007      low\n",
       "1009      low\n",
       "         ... \n",
       "56037     low\n",
       "56039    high\n",
       "56041     low\n",
       "56043     low\n",
       "56045     low\n",
       "Name: case_class, Length: 3058, dtype: category\n",
       "Categories (2, object): ['low' < 'high']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bin and cut the case_pct column into 2 classifications\n",
    "# q = df['case_pct'].quantile(.75)\n",
    "q = df['case_pct'].quantile(.9)\n",
    "bins = [0, q , 40]\n",
    "labels = ['low','high']\n",
    "df['case_class'] = pd.cut(df['case_pct'], bins, labels = labels)\n",
    "df['case_class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0da9118",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "low     2728\n",
       "high     306\n",
       "Name: case_class, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['case_class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0b8f650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_year_cases</th>\n",
       "      <th>AREA_SQMI</th>\n",
       "      <th>E_TOTPOP</th>\n",
       "      <th>E_HU</th>\n",
       "      <th>E_HH</th>\n",
       "      <th>E_POV</th>\n",
       "      <th>E_UNEMP</th>\n",
       "      <th>E_PCI</th>\n",
       "      <th>E_NOHSDP</th>\n",
       "      <th>E_AGE65</th>\n",
       "      <th>...</th>\n",
       "      <th>Income Per Capita</th>\n",
       "      <th>Neuroticism</th>\n",
       "      <th>Openness</th>\n",
       "      <th>Religiosity</th>\n",
       "      <th>Risk Taking</th>\n",
       "      <th>Selflessness</th>\n",
       "      <th>Tolerance</th>\n",
       "      <th>Work Ethic</th>\n",
       "      <th>dem_pct</th>\n",
       "      <th>case_class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FIPS</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>6589</td>\n",
       "      <td>594.443459</td>\n",
       "      <td>55200.0</td>\n",
       "      <td>23315.0</td>\n",
       "      <td>21115.0</td>\n",
       "      <td>8422.0</td>\n",
       "      <td>1065.0</td>\n",
       "      <td>29372.0</td>\n",
       "      <td>4204.0</td>\n",
       "      <td>8050.0</td>\n",
       "      <td>...</td>\n",
       "      <td>26168.0</td>\n",
       "      <td>77.925476</td>\n",
       "      <td>78.222354</td>\n",
       "      <td>91.106719</td>\n",
       "      <td>53.333333</td>\n",
       "      <td>82.142857</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>60.380952</td>\n",
       "      <td>27.018365</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>20505</td>\n",
       "      <td>1589.793007</td>\n",
       "      <td>208107.0</td>\n",
       "      <td>111945.0</td>\n",
       "      <td>78622.0</td>\n",
       "      <td>21653.0</td>\n",
       "      <td>4343.0</td>\n",
       "      <td>31203.0</td>\n",
       "      <td>14310.0</td>\n",
       "      <td>40665.0</td>\n",
       "      <td>...</td>\n",
       "      <td>28069.0</td>\n",
       "      <td>77.232120</td>\n",
       "      <td>80.086368</td>\n",
       "      <td>71.771566</td>\n",
       "      <td>67.272980</td>\n",
       "      <td>75.586018</td>\n",
       "      <td>66.983549</td>\n",
       "      <td>70.972246</td>\n",
       "      <td>22.409030</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>2227</td>\n",
       "      <td>885.001636</td>\n",
       "      <td>25782.0</td>\n",
       "      <td>11937.0</td>\n",
       "      <td>9186.0</td>\n",
       "      <td>6597.0</td>\n",
       "      <td>918.0</td>\n",
       "      <td>18461.0</td>\n",
       "      <td>4901.0</td>\n",
       "      <td>4634.0</td>\n",
       "      <td>...</td>\n",
       "      <td>17249.0</td>\n",
       "      <td>80.375206</td>\n",
       "      <td>78.783778</td>\n",
       "      <td>73.657368</td>\n",
       "      <td>76.066481</td>\n",
       "      <td>78.753019</td>\n",
       "      <td>65.170377</td>\n",
       "      <td>68.704105</td>\n",
       "      <td>45.788173</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>2542</td>\n",
       "      <td>622.461089</td>\n",
       "      <td>22527.0</td>\n",
       "      <td>9161.0</td>\n",
       "      <td>6840.0</td>\n",
       "      <td>2863.0</td>\n",
       "      <td>658.0</td>\n",
       "      <td>20199.0</td>\n",
       "      <td>2650.0</td>\n",
       "      <td>3661.0</td>\n",
       "      <td>...</td>\n",
       "      <td>18988.0</td>\n",
       "      <td>80.813736</td>\n",
       "      <td>77.837027</td>\n",
       "      <td>69.974652</td>\n",
       "      <td>75.136154</td>\n",
       "      <td>76.929754</td>\n",
       "      <td>69.859503</td>\n",
       "      <td>67.931677</td>\n",
       "      <td>20.698280</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>6444</td>\n",
       "      <td>644.830460</td>\n",
       "      <td>57645.0</td>\n",
       "      <td>24222.0</td>\n",
       "      <td>20600.0</td>\n",
       "      <td>8220.0</td>\n",
       "      <td>909.0</td>\n",
       "      <td>22656.0</td>\n",
       "      <td>7861.0</td>\n",
       "      <td>10233.0</td>\n",
       "      <td>...</td>\n",
       "      <td>21033.0</td>\n",
       "      <td>78.764620</td>\n",
       "      <td>78.193105</td>\n",
       "      <td>92.045455</td>\n",
       "      <td>57.603815</td>\n",
       "      <td>79.307632</td>\n",
       "      <td>64.953288</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>9.569378</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56037</th>\n",
       "      <td>4022</td>\n",
       "      <td>10426.975725</td>\n",
       "      <td>44117.0</td>\n",
       "      <td>19628.0</td>\n",
       "      <td>15871.0</td>\n",
       "      <td>5237.0</td>\n",
       "      <td>1213.0</td>\n",
       "      <td>32624.0</td>\n",
       "      <td>2549.0</td>\n",
       "      <td>4721.0</td>\n",
       "      <td>...</td>\n",
       "      <td>30945.0</td>\n",
       "      <td>79.384759</td>\n",
       "      <td>79.347081</td>\n",
       "      <td>68.147062</td>\n",
       "      <td>73.938691</td>\n",
       "      <td>76.390464</td>\n",
       "      <td>67.420658</td>\n",
       "      <td>70.956334</td>\n",
       "      <td>22.894957</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56039</th>\n",
       "      <td>3609</td>\n",
       "      <td>3996.844622</td>\n",
       "      <td>23059.0</td>\n",
       "      <td>13680.0</td>\n",
       "      <td>9158.0</td>\n",
       "      <td>1619.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>53703.0</td>\n",
       "      <td>958.0</td>\n",
       "      <td>3135.0</td>\n",
       "      <td>...</td>\n",
       "      <td>46499.0</td>\n",
       "      <td>71.547359</td>\n",
       "      <td>80.522872</td>\n",
       "      <td>65.399695</td>\n",
       "      <td>79.598153</td>\n",
       "      <td>79.698193</td>\n",
       "      <td>70.877600</td>\n",
       "      <td>70.938645</td>\n",
       "      <td>66.599040</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56041</th>\n",
       "      <td>2128</td>\n",
       "      <td>2081.719807</td>\n",
       "      <td>20609.0</td>\n",
       "      <td>8972.0</td>\n",
       "      <td>7735.0</td>\n",
       "      <td>2552.0</td>\n",
       "      <td>614.0</td>\n",
       "      <td>27009.0</td>\n",
       "      <td>934.0</td>\n",
       "      <td>2498.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25636.0</td>\n",
       "      <td>78.771570</td>\n",
       "      <td>77.859042</td>\n",
       "      <td>67.603416</td>\n",
       "      <td>69.705859</td>\n",
       "      <td>73.332067</td>\n",
       "      <td>67.404487</td>\n",
       "      <td>69.299391</td>\n",
       "      <td>16.819960</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56043</th>\n",
       "      <td>891</td>\n",
       "      <td>2238.672972</td>\n",
       "      <td>8129.0</td>\n",
       "      <td>3868.0</td>\n",
       "      <td>3422.0</td>\n",
       "      <td>984.0</td>\n",
       "      <td>253.0</td>\n",
       "      <td>27556.0</td>\n",
       "      <td>590.0</td>\n",
       "      <td>1686.0</td>\n",
       "      <td>...</td>\n",
       "      <td>26325.0</td>\n",
       "      <td>76.249370</td>\n",
       "      <td>77.658224</td>\n",
       "      <td>67.412774</td>\n",
       "      <td>82.820701</td>\n",
       "      <td>78.925326</td>\n",
       "      <td>74.628788</td>\n",
       "      <td>70.050103</td>\n",
       "      <td>16.145833</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56045</th>\n",
       "      <td>633</td>\n",
       "      <td>2398.003891</td>\n",
       "      <td>7100.0</td>\n",
       "      <td>3565.0</td>\n",
       "      <td>3062.0</td>\n",
       "      <td>1171.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>29152.0</td>\n",
       "      <td>389.0</td>\n",
       "      <td>1340.0</td>\n",
       "      <td>...</td>\n",
       "      <td>29493.0</td>\n",
       "      <td>79.961075</td>\n",
       "      <td>76.977099</td>\n",
       "      <td>71.535519</td>\n",
       "      <td>75.406846</td>\n",
       "      <td>76.730879</td>\n",
       "      <td>68.422269</td>\n",
       "      <td>69.413532</td>\n",
       "      <td>10.112360</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3058 rows × 104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       first_year_cases     AREA_SQMI  E_TOTPOP      E_HU     E_HH    E_POV  \\\n",
       "FIPS                                                                          \n",
       "1001               6589    594.443459   55200.0   23315.0  21115.0   8422.0   \n",
       "1003              20505   1589.793007  208107.0  111945.0  78622.0  21653.0   \n",
       "1005               2227    885.001636   25782.0   11937.0   9186.0   6597.0   \n",
       "1007               2542    622.461089   22527.0    9161.0   6840.0   2863.0   \n",
       "1009               6444    644.830460   57645.0   24222.0  20600.0   8220.0   \n",
       "...                 ...           ...       ...       ...      ...      ...   \n",
       "56037              4022  10426.975725   44117.0   19628.0  15871.0   5237.0   \n",
       "56039              3609   3996.844622   23059.0   13680.0   9158.0   1619.0   \n",
       "56041              2128   2081.719807   20609.0    8972.0   7735.0   2552.0   \n",
       "56043               891   2238.672972    8129.0    3868.0   3422.0    984.0   \n",
       "56045               633   2398.003891    7100.0    3565.0   3062.0   1171.0   \n",
       "\n",
       "       E_UNEMP    E_PCI  E_NOHSDP  E_AGE65  ...  Income Per Capita  \\\n",
       "FIPS                                        ...                      \n",
       "1001    1065.0  29372.0    4204.0   8050.0  ...            26168.0   \n",
       "1003    4343.0  31203.0   14310.0  40665.0  ...            28069.0   \n",
       "1005     918.0  18461.0    4901.0   4634.0  ...            17249.0   \n",
       "1007     658.0  20199.0    2650.0   3661.0  ...            18988.0   \n",
       "1009     909.0  22656.0    7861.0  10233.0  ...            21033.0   \n",
       "...        ...      ...       ...      ...  ...                ...   \n",
       "56037   1213.0  32624.0    2549.0   4721.0  ...            30945.0   \n",
       "56039    210.0  53703.0     958.0   3135.0  ...            46499.0   \n",
       "56041    614.0  27009.0     934.0   2498.0  ...            25636.0   \n",
       "56043    253.0  27556.0     590.0   1686.0  ...            26325.0   \n",
       "56045    117.0  29152.0     389.0   1340.0  ...            29493.0   \n",
       "\n",
       "       Neuroticism   Openness  Religiosity  Risk Taking  Selflessness  \\\n",
       "FIPS                                                                    \n",
       "1001     77.925476  78.222354    91.106719    53.333333     82.142857   \n",
       "1003     77.232120  80.086368    71.771566    67.272980     75.586018   \n",
       "1005     80.375206  78.783778    73.657368    76.066481     78.753019   \n",
       "1007     80.813736  77.837027    69.974652    75.136154     76.929754   \n",
       "1009     78.764620  78.193105    92.045455    57.603815     79.307632   \n",
       "...            ...        ...          ...          ...           ...   \n",
       "56037    79.384759  79.347081    68.147062    73.938691     76.390464   \n",
       "56039    71.547359  80.522872    65.399695    79.598153     79.698193   \n",
       "56041    78.771570  77.859042    67.603416    69.705859     73.332067   \n",
       "56043    76.249370  77.658224    67.412774    82.820701     78.925326   \n",
       "56045    79.961075  76.977099    71.535519    75.406846     76.730879   \n",
       "\n",
       "       Tolerance  Work Ethic    dem_pct  case_class  \n",
       "FIPS                                                 \n",
       "1001   70.000000   60.380952  27.018365         low  \n",
       "1003   66.983549   70.972246  22.409030         low  \n",
       "1005   65.170377   68.704105  45.788173         low  \n",
       "1007   69.859503   67.931677  20.698280         low  \n",
       "1009   64.953288   76.000000   9.569378         low  \n",
       "...          ...         ...        ...         ...  \n",
       "56037  67.420658   70.956334  22.894957         low  \n",
       "56039  70.877600   70.938645  66.599040        high  \n",
       "56041  67.404487   69.299391  16.819960         low  \n",
       "56043  74.628788   70.050103  16.145833         low  \n",
       "56045  68.422269   69.413532  10.112360         low  \n",
       "\n",
       "[3058 rows x 104 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop unneeded columns\n",
    "df = df.drop('case_pct', axis =1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "664b3ed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_year_cases</th>\n",
       "      <th>AREA_SQMI</th>\n",
       "      <th>E_TOTPOP</th>\n",
       "      <th>E_HU</th>\n",
       "      <th>E_HH</th>\n",
       "      <th>E_POV</th>\n",
       "      <th>E_UNEMP</th>\n",
       "      <th>E_PCI</th>\n",
       "      <th>E_NOHSDP</th>\n",
       "      <th>E_AGE65</th>\n",
       "      <th>...</th>\n",
       "      <th>Neuroticism</th>\n",
       "      <th>Openness</th>\n",
       "      <th>Religiosity</th>\n",
       "      <th>Risk Taking</th>\n",
       "      <th>Selflessness</th>\n",
       "      <th>Tolerance</th>\n",
       "      <th>Work Ethic</th>\n",
       "      <th>dem_pct</th>\n",
       "      <th>case_class_low</th>\n",
       "      <th>case_class_high</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FIPS</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>6589</td>\n",
       "      <td>594.443459</td>\n",
       "      <td>55200.0</td>\n",
       "      <td>23315.0</td>\n",
       "      <td>21115.0</td>\n",
       "      <td>8422.0</td>\n",
       "      <td>1065.0</td>\n",
       "      <td>29372.0</td>\n",
       "      <td>4204.0</td>\n",
       "      <td>8050.0</td>\n",
       "      <td>...</td>\n",
       "      <td>77.925476</td>\n",
       "      <td>78.222354</td>\n",
       "      <td>91.106719</td>\n",
       "      <td>53.333333</td>\n",
       "      <td>82.142857</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>60.380952</td>\n",
       "      <td>27.018365</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>20505</td>\n",
       "      <td>1589.793007</td>\n",
       "      <td>208107.0</td>\n",
       "      <td>111945.0</td>\n",
       "      <td>78622.0</td>\n",
       "      <td>21653.0</td>\n",
       "      <td>4343.0</td>\n",
       "      <td>31203.0</td>\n",
       "      <td>14310.0</td>\n",
       "      <td>40665.0</td>\n",
       "      <td>...</td>\n",
       "      <td>77.232120</td>\n",
       "      <td>80.086368</td>\n",
       "      <td>71.771566</td>\n",
       "      <td>67.272980</td>\n",
       "      <td>75.586018</td>\n",
       "      <td>66.983549</td>\n",
       "      <td>70.972246</td>\n",
       "      <td>22.409030</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>2227</td>\n",
       "      <td>885.001636</td>\n",
       "      <td>25782.0</td>\n",
       "      <td>11937.0</td>\n",
       "      <td>9186.0</td>\n",
       "      <td>6597.0</td>\n",
       "      <td>918.0</td>\n",
       "      <td>18461.0</td>\n",
       "      <td>4901.0</td>\n",
       "      <td>4634.0</td>\n",
       "      <td>...</td>\n",
       "      <td>80.375206</td>\n",
       "      <td>78.783778</td>\n",
       "      <td>73.657368</td>\n",
       "      <td>76.066481</td>\n",
       "      <td>78.753019</td>\n",
       "      <td>65.170377</td>\n",
       "      <td>68.704105</td>\n",
       "      <td>45.788173</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>2542</td>\n",
       "      <td>622.461089</td>\n",
       "      <td>22527.0</td>\n",
       "      <td>9161.0</td>\n",
       "      <td>6840.0</td>\n",
       "      <td>2863.0</td>\n",
       "      <td>658.0</td>\n",
       "      <td>20199.0</td>\n",
       "      <td>2650.0</td>\n",
       "      <td>3661.0</td>\n",
       "      <td>...</td>\n",
       "      <td>80.813736</td>\n",
       "      <td>77.837027</td>\n",
       "      <td>69.974652</td>\n",
       "      <td>75.136154</td>\n",
       "      <td>76.929754</td>\n",
       "      <td>69.859503</td>\n",
       "      <td>67.931677</td>\n",
       "      <td>20.698280</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>6444</td>\n",
       "      <td>644.830460</td>\n",
       "      <td>57645.0</td>\n",
       "      <td>24222.0</td>\n",
       "      <td>20600.0</td>\n",
       "      <td>8220.0</td>\n",
       "      <td>909.0</td>\n",
       "      <td>22656.0</td>\n",
       "      <td>7861.0</td>\n",
       "      <td>10233.0</td>\n",
       "      <td>...</td>\n",
       "      <td>78.764620</td>\n",
       "      <td>78.193105</td>\n",
       "      <td>92.045455</td>\n",
       "      <td>57.603815</td>\n",
       "      <td>79.307632</td>\n",
       "      <td>64.953288</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>9.569378</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56037</th>\n",
       "      <td>4022</td>\n",
       "      <td>10426.975725</td>\n",
       "      <td>44117.0</td>\n",
       "      <td>19628.0</td>\n",
       "      <td>15871.0</td>\n",
       "      <td>5237.0</td>\n",
       "      <td>1213.0</td>\n",
       "      <td>32624.0</td>\n",
       "      <td>2549.0</td>\n",
       "      <td>4721.0</td>\n",
       "      <td>...</td>\n",
       "      <td>79.384759</td>\n",
       "      <td>79.347081</td>\n",
       "      <td>68.147062</td>\n",
       "      <td>73.938691</td>\n",
       "      <td>76.390464</td>\n",
       "      <td>67.420658</td>\n",
       "      <td>70.956334</td>\n",
       "      <td>22.894957</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56039</th>\n",
       "      <td>3609</td>\n",
       "      <td>3996.844622</td>\n",
       "      <td>23059.0</td>\n",
       "      <td>13680.0</td>\n",
       "      <td>9158.0</td>\n",
       "      <td>1619.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>53703.0</td>\n",
       "      <td>958.0</td>\n",
       "      <td>3135.0</td>\n",
       "      <td>...</td>\n",
       "      <td>71.547359</td>\n",
       "      <td>80.522872</td>\n",
       "      <td>65.399695</td>\n",
       "      <td>79.598153</td>\n",
       "      <td>79.698193</td>\n",
       "      <td>70.877600</td>\n",
       "      <td>70.938645</td>\n",
       "      <td>66.599040</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56041</th>\n",
       "      <td>2128</td>\n",
       "      <td>2081.719807</td>\n",
       "      <td>20609.0</td>\n",
       "      <td>8972.0</td>\n",
       "      <td>7735.0</td>\n",
       "      <td>2552.0</td>\n",
       "      <td>614.0</td>\n",
       "      <td>27009.0</td>\n",
       "      <td>934.0</td>\n",
       "      <td>2498.0</td>\n",
       "      <td>...</td>\n",
       "      <td>78.771570</td>\n",
       "      <td>77.859042</td>\n",
       "      <td>67.603416</td>\n",
       "      <td>69.705859</td>\n",
       "      <td>73.332067</td>\n",
       "      <td>67.404487</td>\n",
       "      <td>69.299391</td>\n",
       "      <td>16.819960</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56043</th>\n",
       "      <td>891</td>\n",
       "      <td>2238.672972</td>\n",
       "      <td>8129.0</td>\n",
       "      <td>3868.0</td>\n",
       "      <td>3422.0</td>\n",
       "      <td>984.0</td>\n",
       "      <td>253.0</td>\n",
       "      <td>27556.0</td>\n",
       "      <td>590.0</td>\n",
       "      <td>1686.0</td>\n",
       "      <td>...</td>\n",
       "      <td>76.249370</td>\n",
       "      <td>77.658224</td>\n",
       "      <td>67.412774</td>\n",
       "      <td>82.820701</td>\n",
       "      <td>78.925326</td>\n",
       "      <td>74.628788</td>\n",
       "      <td>70.050103</td>\n",
       "      <td>16.145833</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56045</th>\n",
       "      <td>633</td>\n",
       "      <td>2398.003891</td>\n",
       "      <td>7100.0</td>\n",
       "      <td>3565.0</td>\n",
       "      <td>3062.0</td>\n",
       "      <td>1171.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>29152.0</td>\n",
       "      <td>389.0</td>\n",
       "      <td>1340.0</td>\n",
       "      <td>...</td>\n",
       "      <td>79.961075</td>\n",
       "      <td>76.977099</td>\n",
       "      <td>71.535519</td>\n",
       "      <td>75.406846</td>\n",
       "      <td>76.730879</td>\n",
       "      <td>68.422269</td>\n",
       "      <td>69.413532</td>\n",
       "      <td>10.112360</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3058 rows × 105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       first_year_cases     AREA_SQMI  E_TOTPOP      E_HU     E_HH    E_POV  \\\n",
       "FIPS                                                                          \n",
       "1001               6589    594.443459   55200.0   23315.0  21115.0   8422.0   \n",
       "1003              20505   1589.793007  208107.0  111945.0  78622.0  21653.0   \n",
       "1005               2227    885.001636   25782.0   11937.0   9186.0   6597.0   \n",
       "1007               2542    622.461089   22527.0    9161.0   6840.0   2863.0   \n",
       "1009               6444    644.830460   57645.0   24222.0  20600.0   8220.0   \n",
       "...                 ...           ...       ...       ...      ...      ...   \n",
       "56037              4022  10426.975725   44117.0   19628.0  15871.0   5237.0   \n",
       "56039              3609   3996.844622   23059.0   13680.0   9158.0   1619.0   \n",
       "56041              2128   2081.719807   20609.0    8972.0   7735.0   2552.0   \n",
       "56043               891   2238.672972    8129.0    3868.0   3422.0    984.0   \n",
       "56045               633   2398.003891    7100.0    3565.0   3062.0   1171.0   \n",
       "\n",
       "       E_UNEMP    E_PCI  E_NOHSDP  E_AGE65  ...  Neuroticism   Openness  \\\n",
       "FIPS                                        ...                           \n",
       "1001    1065.0  29372.0    4204.0   8050.0  ...    77.925476  78.222354   \n",
       "1003    4343.0  31203.0   14310.0  40665.0  ...    77.232120  80.086368   \n",
       "1005     918.0  18461.0    4901.0   4634.0  ...    80.375206  78.783778   \n",
       "1007     658.0  20199.0    2650.0   3661.0  ...    80.813736  77.837027   \n",
       "1009     909.0  22656.0    7861.0  10233.0  ...    78.764620  78.193105   \n",
       "...        ...      ...       ...      ...  ...          ...        ...   \n",
       "56037   1213.0  32624.0    2549.0   4721.0  ...    79.384759  79.347081   \n",
       "56039    210.0  53703.0     958.0   3135.0  ...    71.547359  80.522872   \n",
       "56041    614.0  27009.0     934.0   2498.0  ...    78.771570  77.859042   \n",
       "56043    253.0  27556.0     590.0   1686.0  ...    76.249370  77.658224   \n",
       "56045    117.0  29152.0     389.0   1340.0  ...    79.961075  76.977099   \n",
       "\n",
       "       Religiosity  Risk Taking  Selflessness  Tolerance  Work Ethic  \\\n",
       "FIPS                                                                   \n",
       "1001     91.106719    53.333333     82.142857  70.000000   60.380952   \n",
       "1003     71.771566    67.272980     75.586018  66.983549   70.972246   \n",
       "1005     73.657368    76.066481     78.753019  65.170377   68.704105   \n",
       "1007     69.974652    75.136154     76.929754  69.859503   67.931677   \n",
       "1009     92.045455    57.603815     79.307632  64.953288   76.000000   \n",
       "...            ...          ...           ...        ...         ...   \n",
       "56037    68.147062    73.938691     76.390464  67.420658   70.956334   \n",
       "56039    65.399695    79.598153     79.698193  70.877600   70.938645   \n",
       "56041    67.603416    69.705859     73.332067  67.404487   69.299391   \n",
       "56043    67.412774    82.820701     78.925326  74.628788   70.050103   \n",
       "56045    71.535519    75.406846     76.730879  68.422269   69.413532   \n",
       "\n",
       "         dem_pct  case_class_low  case_class_high  \n",
       "FIPS                                               \n",
       "1001   27.018365               1                0  \n",
       "1003   22.409030               1                0  \n",
       "1005   45.788173               1                0  \n",
       "1007   20.698280               1                0  \n",
       "1009    9.569378               1                0  \n",
       "...          ...             ...              ...  \n",
       "56037  22.894957               1                0  \n",
       "56039  66.599040               0                1  \n",
       "56041  16.819960               1                0  \n",
       "56043  16.145833               1                0  \n",
       "56045  10.112360               1                0  \n",
       "\n",
       "[3058 rows x 105 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#turn case % classifications into binary \n",
    "df = pd.get_dummies(df, columns = ['case_class'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cfb69257",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2752\n",
       "1     306\n",
       "Name: case_class_high, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['case_class_high'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3dc4e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#seperate targets and features\n",
    "## should i drop the number of cases?\n",
    "X = df.drop(['case_class_low','case_class_high'], axis=1).values\n",
    "y=df['case_class_high'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe3d3924",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a2d4ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3cb693cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3de65d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 100)               10400     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 80)                8080      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 40)                3240      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 41        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,761\n",
      "Trainable params: 21,761\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-07 20:41:12.444500: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net\n",
    "number_input_features = len(X_train[0])\n",
    "# hidden_nodes_layer1 = 100\n",
    "# hidden_nodes_layer2 = 50\n",
    "hidden_nodes_layer1 = 100\n",
    "hidden_nodes_layer2 = 80\n",
    "hidden_nodes_layer3 = 40\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\")\n",
    ")\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"relu\"))\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a209d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a670e197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "72/72 [==============================] - 1s 2ms/step - loss: 220.2316 - accuracy: 0.8247\n",
      "Epoch 2/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 276.3930 - accuracy: 0.8378\n",
      "Epoch 3/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 61.9225 - accuracy: 0.8474\n",
      "Epoch 4/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 60.1193 - accuracy: 0.8421\n",
      "Epoch 5/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 30.0519 - accuracy: 0.8500\n",
      "Epoch 6/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 70.0946 - accuracy: 0.8369\n",
      "Epoch 7/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 31.2346 - accuracy: 0.8382\n",
      "Epoch 8/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 29.5353 - accuracy: 0.8509\n",
      "Epoch 9/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 35.5390 - accuracy: 0.8500\n",
      "Epoch 10/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 24.5400 - accuracy: 0.8740\n",
      "Epoch 11/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 46.9928 - accuracy: 0.8500\n",
      "Epoch 12/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 14.1756 - accuracy: 0.8692\n",
      "Epoch 13/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 19.1297 - accuracy: 0.8705\n",
      "Epoch 14/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 27.5248 - accuracy: 0.8578\n",
      "Epoch 15/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 11.4488 - accuracy: 0.8591\n",
      "Epoch 16/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 17.5667 - accuracy: 0.8766\n",
      "Epoch 17/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 34.8341 - accuracy: 0.8487\n",
      "Epoch 18/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 9.5855 - accuracy: 0.8831\n",
      "Epoch 19/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 22.1468 - accuracy: 0.8487\n",
      "Epoch 20/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 12.0793 - accuracy: 0.8526\n",
      "Epoch 21/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 10.7979 - accuracy: 0.8679\n",
      "Epoch 22/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 11.7550 - accuracy: 0.8522\n",
      "Epoch 23/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 2.2534 - accuracy: 0.8949\n",
      "Epoch 24/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 2.1021 - accuracy: 0.9027\n",
      "Epoch 25/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.1051 - accuracy: 0.9097\n",
      "Epoch 26/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0865 - accuracy: 0.9049\n",
      "Epoch 27/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9972 - accuracy: 0.9167\n",
      "Epoch 28/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0841 - accuracy: 0.9184\n",
      "Epoch 29/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 10.0646 - accuracy: 0.8971\n",
      "Epoch 30/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 4.9592 - accuracy: 0.8722\n",
      "Epoch 31/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 8.5072 - accuracy: 0.8884\n",
      "Epoch 32/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 4.1525 - accuracy: 0.8731\n",
      "Epoch 33/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 3.0277 - accuracy: 0.8945\n",
      "Epoch 34/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 3.4228 - accuracy: 0.8993\n",
      "Epoch 35/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 4.7330 - accuracy: 0.8570\n",
      "Epoch 36/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 4.8830 - accuracy: 0.8657\n",
      "Epoch 37/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 2.3036 - accuracy: 0.9119\n",
      "Epoch 38/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 7.6274 - accuracy: 0.8705\n",
      "Epoch 39/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9365 - accuracy: 0.9241\n",
      "Epoch 40/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9384 - accuracy: 0.9180\n",
      "Epoch 41/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.4225 - accuracy: 0.9232\n",
      "Epoch 42/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 3.7833 - accuracy: 0.8818\n",
      "Epoch 43/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.5660 - accuracy: 0.9254\n",
      "Epoch 44/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.3407 - accuracy: 0.9368\n",
      "Epoch 45/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 7.3405 - accuracy: 0.8923\n",
      "Epoch 46/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 4.7951 - accuracy: 0.8570\n",
      "Epoch 47/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.5866 - accuracy: 0.8966\n",
      "Epoch 48/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9768 - accuracy: 0.9106\n",
      "Epoch 49/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0295 - accuracy: 0.9049\n",
      "Epoch 50/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 20.2964 - accuracy: 0.8574\n",
      "Epoch 51/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 14.9906 - accuracy: 0.8631\n",
      "Epoch 52/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 17.5059 - accuracy: 0.8530\n",
      "Epoch 53/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 12.9041 - accuracy: 0.8234\n",
      "Epoch 54/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 7.9697 - accuracy: 0.8421\n",
      "Epoch 55/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.2974 - accuracy: 0.8783\n",
      "Epoch 56/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.7010 - accuracy: 0.8857\n",
      "Epoch 57/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8085 - accuracy: 0.8836\n",
      "Epoch 58/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.1640 - accuracy: 0.8809\n",
      "Epoch 59/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.1813 - accuracy: 0.8657\n",
      "Epoch 60/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.4008 - accuracy: 0.9045\n",
      "Epoch 61/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.3372 - accuracy: 0.9211\n",
      "Epoch 62/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.3279 - accuracy: 0.9232\n",
      "Epoch 63/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9220 - accuracy: 0.8801\n",
      "Epoch 64/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.4861 - accuracy: 0.9110\n",
      "Epoch 65/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.2334 - accuracy: 0.9328\n",
      "Epoch 66/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.3178 - accuracy: 0.9189\n",
      "Epoch 67/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.2651 - accuracy: 0.9302\n",
      "Epoch 68/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.1866 - accuracy: 0.9446\n",
      "Epoch 69/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.1712 - accuracy: 0.8910\n",
      "Epoch 70/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 2.1041 - accuracy: 0.8997\n",
      "Epoch 71/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.7252 - accuracy: 0.8884\n",
      "Epoch 72/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.2072 - accuracy: 0.8809\n",
      "Epoch 73/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.2467 - accuracy: 0.9350\n",
      "Epoch 74/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.7927 - accuracy: 0.9145\n",
      "Epoch 75/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9095 - accuracy: 0.8857\n",
      "Epoch 76/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9088 - accuracy: 0.8997\n",
      "Epoch 77/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.3162 - accuracy: 0.9189\n",
      "Epoch 78/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.4847 - accuracy: 0.8901\n",
      "Epoch 79/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.2185 - accuracy: 0.9337\n",
      "Epoch 80/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.2464 - accuracy: 0.9307\n",
      "Epoch 81/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.3892 - accuracy: 0.9171\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 0s 2ms/step - loss: 0.1630 - accuracy: 0.9385\n",
      "Epoch 83/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.2803 - accuracy: 0.8648\n",
      "Epoch 84/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.2273 - accuracy: 0.9302\n",
      "Epoch 85/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.1901 - accuracy: 0.9307\n",
      "Epoch 86/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.2191 - accuracy: 0.9381\n",
      "Epoch 87/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8079 - accuracy: 0.8809\n",
      "Epoch 88/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.2025 - accuracy: 0.9337\n",
      "Epoch 89/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.1501 - accuracy: 0.9424\n",
      "Epoch 90/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.1429 - accuracy: 0.9477\n",
      "Epoch 91/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.1638 - accuracy: 0.9442\n",
      "Epoch 92/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.1346 - accuracy: 0.9477\n",
      "Epoch 93/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0018 - accuracy: 0.8727\n",
      "Epoch 94/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.6460 - accuracy: 0.8962\n",
      "Epoch 95/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 3.3895 - accuracy: 0.8644\n",
      "Epoch 96/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 4.8242 - accuracy: 0.8679\n",
      "Epoch 97/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 16.0262 - accuracy: 0.8635\n",
      "Epoch 98/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 5.6903 - accuracy: 0.8474\n",
      "Epoch 99/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 7.1474 - accuracy: 0.8338\n",
      "Epoch 100/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 2.6895 - accuracy: 0.8836\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn.fit(X_train,y_train,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9d122ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 - 0s - loss: 1.7147 - accuracy: 0.8967 - 182ms/epoch - 8ms/step\n",
      "Loss: 1.714719295501709, Accuracy: 0.8967320322990417\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "581f5f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[681,   0],\n",
       "       [ 83,   1]], dtype=int32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=nn.predict(X_test)\n",
    "con_mat = tf.math.confusion_matrix(labels=y_test, predictions=y_pred)\n",
    "con_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8dd727",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b97482",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
